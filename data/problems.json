[
    {
        "question": "Two Sum",
        "description": "Given an array of integers `nums` and an integer `target`, find the indices of the two numbers in `nums` that add up to `target`. You may assume that each input would have exactly one solution, and you may not use the same element twice.",
        "approaches": [
            "Approach 1: Brute Force. Iterate through each element `x` in `nums` and check if `target - x` exists in the remaining part of the array. This involves nested loops. The outer loop iterates from `i = 0` to `n-1`, and the inner loop iterates from `j = i+1` to `n-1`. If `nums[i] + nums[j] == target`, return `{i, j}`. The time complexity is O(n^2) because of the nested loops. The space complexity is O(1) as no extra space is used.",
            "Approach 2: Two-Pass Hash Table. First, iterate through the `nums` array and add each element's value and its index to a hash table. Then, iterate through the `nums` array again. For each element `nums[i]`, find its complement `target - nums[i]`. If the complement exists in the hash table and its index is not equal to `i`, return `{i, complement_index}`. The time complexity is O(n) because we iterate through the array twice. The space complexity is O(n) because we store the elements in a hash table.",
            "Approach 3: One-Pass Hash Table. Iterate through the `nums` array. For each element `nums[i]`, find its complement `target - nums[i]`. Check if the complement exists in the hash table. If it exists, return `{hash_table[complement], i}`. If it doesn't exist, add `nums[i]` and its index `i` to the hash table. The time complexity is O(n) since we traverse the list only once, and hash table lookups take O(1) time on average. The space complexity is O(n) because we store the elements in a hash table."
        ],
        "ques_num": 1
    },
    {
        "question": "Add Two Numbers",
        "description": "You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order, and each of their nodes contains a single digit. Add the two numbers and return the sum as a linked list.",
        "approaches": [
            "Approach 1: Convert Linked Lists to Integers, Sum, and Convert Back. Iterate through both linked lists, constructing integers from the reversed digits. Sum the two integers. Convert the resulting sum back into a linked list, with digits in reverse order. This approach is limited by the maximum size of integers that can be represented. Time complexity: O(m+n) to convert the lists to integers, plus O(log(sum)) to convert the sum back to a linked list, where m and n are the lengths of the linked lists. Space complexity: O(1) excluding the result list, but O(log(sum)) including the result list.",
            "Approach 2: Elementary Math with Constant Space Improvement. Perform digit-by-digit addition directly on the linked lists, keeping track of a carry. Iterate through both lists simultaneously, summing the corresponding digits along with the carry from the previous step. Store the result (sum % 10) in a new node and update the carry (sum / 10). Continue until both lists are exhausted and the carry is zero. This approach addresses the integer overflow issue of Approach 1 but still modifies the original lists. Time complexity: O(max(m, n)), where m and n are the lengths of the linked lists. Space complexity: O(1) excluding the result list, O(max(m, n)) including the result list.",
            "Approach 3: Elementary Math with Dummy Head. This approach is the same as Approach 2 (digit-by-digit addition with carry), but uses a dummy head node to simplify the creation of the result linked list. Initialize a dummy head node. Iterate through both linked lists, summing corresponding digits and the carry. Create a new node with the digit (sum % 10), append it to the current node, and update the carry. Advance the current node, l1 and l2. After the loop, if a carry remains, create a new node for it. Return the next of the dummy head. Time complexity: O(max(m, n)), where m and n are the lengths of the linked lists. Space complexity: O(max(m, n) + 1) for the new linked list plus one dummy node, where m and n are the lengths of the linked lists. This approach avoids modifying the input lists and provides a cleaner implementation using the dummy head."
        ],
        "ques_num": 2
    },
    {
        "question": "Longest Substring Without Repeating Characters",
        "description": "Given a string, find the length of the longest substring without repeating characters.",
        "approaches": [
            "Approach 1: Brute Force. Enumerate all possible substrings of the given string using nested loops. For each substring, check if it contains any repeating characters by iterating through its characters and using a set or hash table to track seen characters. If a repeating character is found, the substring is invalid. Keep track of the maximum length of the valid substrings encountered. Time complexity: O(n^3), where n is the length of the string. This is because there are O(n^2) substrings, and checking each substring for unique characters takes O(n) time. Space complexity: O(min(n, m)), where m is the size of the character set, due to the set used to store unique characters.",
            "Approach 2: Sliding Window with a Set. Use a sliding window approach to maintain a window of characters without repetition. Use a set (or hash table) to keep track of the characters currently in the window. Expand the window to the right until a repeating character is encountered. When a repeating character is found, shrink the window from the left until the repeating character is removed. Keep track of the maximum window size encountered. Time complexity: O(n), where n is the length of the string. Each character will be visited at most twice by the two pointers. Space complexity: O(min(n, m)), where m is the size of the character set, due to the set used to store unique characters in the window.",
            "Approach 3: Sliding Window Optimized with a Map. Use a sliding window approach similar to Approach 2, but instead of a set, use a map (or array) to store the most recent index of each character. When a repeating character is encountered, move the left pointer of the window directly to the position after the previous occurrence of the repeating character. This avoids unnecessary shrinking of the window. Time complexity: O(n), where n is the length of the string. Each character will be visited at most once. Space complexity: O(min(n, m)), where m is the size of the character set, due to the map used to store character indices. This is the most optimal approach as it avoids redundant checks and unnecessary iterations compared to the other two approaches."
        ],
        "ques_num": 3
    },
    {
        "question": "Longest Palindromic Substring",
        "description": "Given a string, find the longest palindromic substring.",
        "approaches": [
            "Approach 1: Brute Force. Generate all possible substrings of the given string, and for each substring, check if it is a palindrome. Keep track of the longest palindromic substring found so far. This involves three nested loops: the outer two loops to generate all substrings (O(n^2)), and the inner loop to check if the substring is a palindrome (O(n)). Therefore, the overall time complexity is O(n^3) and the space complexity is O(1).",
            "Approach 2: Dynamic Programming. Create a 2D boolean table `dp[i][j]` where `dp[i][j]` is true if the substring `str[i...j]` is a palindrome, otherwise false. Fill the table in a bottom-up manner. The base cases are single characters (`dp[i][i] = true`) and two-character substrings (`dp[i][i+1] = (str[i] == str[i+1])`). For substrings of length 3 or more, `dp[i][j] = (str[i] == str[j] && dp[i+1][j-1])`. While filling the table, keep track of the longest palindromic substring. The time complexity is O(n^2) because we iterate through all possible substrings to fill the dp table, and the space complexity is O(n^2) due to the dp table.",
            "Approach 3: Expand Around Center. Iterate through each character of the string and consider it as a potential center of a palindrome. For each character, expand outwards to the left and right, checking for palindromes of odd length. Similarly, consider each pair of adjacent characters as a potential center and expand outwards to check for palindromes of even length. Keep track of the longest palindromic substring found. Since expanding a palindrome around its center could take O(n) time, and we iterate through each character/pair of characters of the string which takes O(n) time, the overall time complexity is O(n^2). The space complexity is O(1) as we only use a constant amount of extra space."
        ],
        "ques_num": 5
    },
    {
        "question": "Zigzag Conversion",
        "description": "Given a string and a number of rows, write the string in a zig-zag pattern on a given number of rows and then read line by line.",
        "approaches": [
            "Approach 1: Simulate Zig-Zag Movement using a Matrix. Create a 2D matrix (array) of size `numRows x numCols` where `numCols` is calculated based on the input string length and `numRows`. Traverse the matrix in a zig-zag order, filling it with characters from the input string. Finally, read the matrix row by row, ignoring empty cells, to construct the output string. Time Complexity: O(n * numRows), Space Complexity: O(n * numRows). This approach uses extra space for the matrix, which can be significant for large inputs and `numRows`.",
            "Approach 2: String Traversal with Jump Pattern Calculation. Observe the pattern of character indices in the zig-zag arrangement. Calculate the jump distances between characters in each row based on `numRows`. Iterate through each row and traverse the input string using the calculated jump pattern to build the output string. Time Complexity: O(n), Space Complexity: O(1). This approach avoids the extra space of the matrix but requires careful calculation of jump distances and index management.",
            "Approach 3: Direct Calculation of Zig-Zag String Indices. Instead of simulating the zig-zag pattern or explicitly calculating jump distances, directly compute the index of each character in the zig-zag string. This can be achieved by analyzing the cycle of the zig-zag pattern and determining the position of each character within the cycle. Time Complexity: O(n), Space Complexity: O(1). This approach is the most optimal as it avoids extra space and performs only necessary calculations to construct the output string directly."
        ],
        "ques_num": 6
    },
    {
        "question": "Reverse Integer",
        "description": "Given a 32-bit signed integer, reverse digits of an integer. Assume we are dealing with an environment which could only store integers within the 32-bit signed integer range: [\u22122^31,  2^31 \u2212 1]. For the purpose of this problem, assume that your function returns 0 when the reversed integer overflows.",
        "approaches": [
            "Approach 1: String Conversion and Reversal. Convert the integer to a string, reverse the string, and then convert it back to an integer. Check for overflow by comparing the result against the maximum and minimum 32-bit integer values. This is the least efficient approach due to the overhead of string conversions. Time complexity: O(n) where n is the number of digits. Space complexity: O(n) to store the reversed string.",
            "Approach 2: Iterative Pop and Push with Overflow Check (using long). Iteratively 'pop' the last digit of the input integer and 'push' it to the reversed integer. Before pushing, check if the reversed integer (multiplied by 10) would overflow the 32-bit range. If it would, return 0. This approach avoids string conversions but uses `long` type to store intermediate results, which is less desirable than avoiding overflow with integer arithmetic. Time complexity: O(log(x)), where x is the input integer. Space complexity: O(1).",
            "Approach 3: Iterative Pop and Push with Optimized Overflow Check (without using long). Iteratively 'pop' the last digit of the input integer and 'push' it to the reversed integer. Before pushing, check for potential overflow by comparing the current reversed integer with `Integer.MAX_VALUE / 10` and `Integer.MIN_VALUE / 10`. If `rev > Integer.MAX_VALUE / 10` or `rev < Integer.MIN_VALUE / 10`, an overflow will occur. If `rev == Integer.MAX_VALUE / 10` and the popped digit is greater than 7, or `rev == Integer.MIN_VALUE / 10` and the popped digit is less than -8, an overflow will occur. This avoids using `long` type, making it memory efficient and preventing overflow based on integer range. Time complexity: O(log(x)) where x is the input integer. Space complexity: O(1)."
        ],
        "ques_num": 7
    },
    {
        "question": "String to Integer (atoi)",
        "description": "Implement a function that converts a given string into a signed 32-bit integer, following specific rules for handling whitespace, signs, non-digit characters, and integer overflow/underflow.",
        "approaches": [
            "Approach 1: Naive String Parsing with Basic Checks. Iterate through the string character by character. Skip leading whitespaces. Identify the sign (+ or -). Accumulate digits until a non-digit character is encountered or the end of the string is reached. After parsing, check for integer overflow/underflow against the 32-bit integer limits (INT_MAX and INT_MIN). If overflow/underflow occurs, clamp the result to INT_MAX or INT_MIN respectively. Time complexity is O(N) where N is the length of the string, and space complexity is O(1) as only a few constant variables are used. This approach lacks proper overflow/underflow handling during the digit accumulation process.",
            "Approach 2: Improved String Parsing with Early Overflow/Underflow Detection. Iterate through the string character by character, similar to Approach 1. However, during the digit accumulation, check for potential overflow/underflow *before* appending the current digit to the result. This can be done by comparing the current result with INT_MAX / 10 and INT_MIN / 10. If the current result is greater than INT_MAX / 10 (or less than INT_MIN / 10), any further digit will cause overflow (or underflow). If the current result is equal to INT_MAX / 10 (or INT_MIN / 10), check if the next digit is greater than 7 (or less than -8) to determine overflow (or underflow). Time complexity is still O(N), but this approach provides more robust overflow/underflow detection. Space complexity remains O(1).",
            "Approach 3: Deterministic Finite Automaton (DFA). Model the problem as a DFA with states representing different parsing stages (e.g., initial whitespace, sign, digit accumulation, invalid input). Each character in the input string triggers a transition between states based on predefined rules. The DFA maintains the current result and sign. Overflow/underflow checks are incorporated into the state transitions to ensure the result stays within the 32-bit integer range. This approach provides a structured and robust way to handle various input scenarios. Time complexity is O(N) as each character is processed once, and space complexity is O(1) because the DFA's state and variables occupy constant space. This is the best approach because it's a more general approach that can also be applied to similar problems, that would otherwise require handling many nested if else conditions which could become very complex.",
            "Approach 4: Using built-in library function. Use `Integer.parseInt()` (Java) or similar built-in functions to directly convert the string to an integer. Wrap this call in a try-catch block to handle `NumberFormatException` which occurs when the string cannot be parsed, and return 0 in that case. This is the shortest and easiest solution, but it relies on the library's implementation of the parsing rules and overflow/underflow handling which may not match the exact requirements of the problem. The time complexity depends on the library's implementation, but is likely O(N). The space complexity is O(1)."
        ],
        "ques_num": 8
    },
    {
        "question": "Palindrome Number",
        "description": "Determine whether an integer is a palindrome. An integer is a palindrome when it reads the same backward as forward.",
        "approaches": [
            "Approach 1: Convert the integer to a string and then check if the string is a palindrome. This involves creating a string representation of the number and comparing characters from both ends towards the middle. Time complexity is O(n), where n is the number of digits. Space complexity is O(n) due to the string creation. This approach is not ideal due to the extra space usage.",
            "Approach 2: Revert the entire number and compare with the original number. This approach involves reversing the integer by repeatedly extracting the last digit and constructing a new reversed integer. A potential issue is integer overflow, which can occur if the reversed number exceeds the maximum integer value. Time complexity is O(log10(n)), where n is the number. Space complexity is O(1).",
            "Approach 3: Revert only half of the number. This avoids the integer overflow issue by only reverting half of the number and then comparing the reversed half with the first half. Edge cases such as negative numbers and numbers ending in zero are handled explicitly. Time complexity is O(log10(n)), where n is the number. Space complexity is O(1). This is the most optimal approach as it avoids integer overflow and requires minimal space."
        ],
        "ques_num": 9
    },
    {
        "question": "Regular Expression Matching",
        "description": "Given a text string and a pattern string containing regular expression characters like '.' (matches any single character) and '*' (matches zero or more occurrences of the preceding character), determine if the pattern matches the text.",
        "approaches": [
            "Approach 1: Naive Recursion. This approach directly translates the problem description into a recursive function. For each character in the pattern, it checks if it matches the current character in the text. If a '*' is encountered, it explores two possibilities: either ignoring the '*' and the preceding character (zero occurrences) or consuming a character from the text if it matches the preceding character (one or more occurrences). The time complexity is exponential, potentially O((T+P)^2+T/2), where T is the text length and P is the pattern length, due to redundant computations. The space complexity is also high, O((T+P)^2+T/2), due to string creation and recursive call stack.",
            "Approach 2: Dynamic Programming (Top-Down with Memoization). This approach improves upon the naive recursion by caching the results of subproblems to avoid redundant computations. A 2D array `dp` is used to store whether `text[i:]` matches `pattern[j:]`. Before making a recursive call, the cache is checked. If the result is already computed, it is returned directly. This reduces the time complexity to O(TP), as each subproblem is solved only once. The space complexity is O(TP) for the cache and O(T+P) for the recursion stack, which can be simplified to O(TP).",
            "Approach 3: Dynamic Programming (Bottom-Up Tabulation). This approach further optimizes the dynamic programming solution by building the `dp` table iteratively from the end of the strings to the beginning. `dp[i][j]` represents whether `text[i:]` matches `pattern[j:]`. The table is filled based on the same logic as the recursive approach, but without the overhead of recursive calls. This approach also achieves a time complexity of O(TP) because each cell in the dp table is computed once. The space complexity is O(TP) for storing the `dp` table. Since it avoids recursive calls, it's often slightly more efficient in practice compared to top-down memoization."
        ],
        "ques_num": 10
    },
    {
        "question": "Container With Most Water",
        "description": "Given n non-negative integers a1, a2, ..., an, where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of the line i is at (i, ai) and (i, 0). Find two lines, which, together with the x-axis forms a container, such that the container contains the most water. The container cannot be slanted.",
        "approaches": [
            "Approach 1: Brute Force. Iterate through all possible pairs of lines (left and right) in the height array. For each pair, calculate the area as the minimum height of the two lines multiplied by the distance between them. Keep track of the maximum area found so far. This involves nested loops, resulting in a time complexity of O(n^2), where n is the number of lines. The space complexity is O(1) as only constant extra space is used.",
            "Approach 2: Two Pointer Approach. Initialize two pointers, one at the beginning (left) and the other at the end (right) of the height array. Calculate the area between the lines pointed to by the left and right pointers. Move the pointer pointing to the shorter line inward. If height[left] <= height[right], increment left; otherwise, decrement right. Continue this process until the left and right pointers meet. Keep track of the maximum area found so far. This approach requires a single pass through the array, resulting in a time complexity of O(n). The space complexity is O(1) as only constant extra space is used.",
            "Approach 3: The two-pointer approach (described in Approach 2) is the most optimal known solution for this problem. It efficiently explores the possible container areas by intelligently reducing the search space at each step. By moving the shorter pointer, the algorithm ensures that the area can potentially increase in the next step. Since it achieves O(n) time complexity with O(1) space complexity, further optimizations are not possible without fundamentally changing the problem constraints or input."
        ],
        "ques_num": 11
    },
    {
        "question": "Integer to Roman",
        "description": "Given an integer, convert it to its Roman numeral representation.",
        "approaches": [
            "Approach 1: Hardcoding the Roman numeral representations for each digit place (thousands, hundreds, tens, and ones). First, extract each digit from the input integer using division and modulo operations. Then, use four separate arrays (one for each place value) to look up the corresponding Roman numeral representation for each digit. Finally, concatenate the Roman numeral representations for each digit to form the final Roman numeral string. The time complexity is O(1) because the number of operations is constant regardless of the input integer's size. The space complexity is also O(1) because the size of the arrays is constant.",
            "Approach 2: Using a lookup table of all possible Roman numeral combinations for each digit place. Create a table (or multiple tables) that map each digit (0-9) to its Roman numeral representation for each place value (thousands, hundreds, tens, ones). Extract the digits of the input integer, then use these digits to look up the corresponding Roman numeral representations in the table(s). Concatenate the results. This approach has a time complexity of O(1) and a space complexity of O(1), but it is less flexible if the Roman numeral system is extended.",
            "Approach 3: Greedy Algorithm. Iterate through a predefined list of Roman numeral symbols and their corresponding integer values, sorted in descending order of value. For each symbol, determine how many times it can be appended to the result without exceeding the input integer. Append the symbol the calculated number of times, and subtract the corresponding integer value from the input integer. Repeat until the input integer becomes zero. This approach has a time complexity of O(1) because there is a finite set of Roman numerals, so the loop iterates a maximum of a fixed number of times. The space complexity is O(1) because the amount of memory used does not change with the size of the input integer."
        ],
        "ques_num": 12
    },
    {
        "question": "Roman to Integer",
        "description": "Given a Roman numeral string, convert it to an integer. The input is assumed to be valid, meaning it follows the standard rules of Roman numeral representation. For example, 'III' is 3, 'IV' is 4, 'IX' is 9, 'LVIII' is 58, and 'MCMXCIV' is 1994.",
        "approaches": [
            "Approach 1: Left-to-right pass. Iterate through the Roman numeral string from left to right. Maintain a map of Roman numeral characters to their integer values (e.g., 'I' -> 1, 'V' -> 5, 'X' -> 10, 'L' -> 50, 'C' -> 100, 'D' -> 500, 'M' -> 1000). If the current character's value is less than the next character's value, subtract the current character's value from the total; otherwise, add it to the total. This approach requires checking for the end of the string to avoid out-of-bounds access. Time complexity: O(n), where n is the length of the Roman numeral string. Space complexity: O(1), as the map has a fixed size.",
            "Approach 2: Left-to-right pass (improved). Similar to Approach 1, but consider two-character combinations (e.g., 'IV', 'IX', 'XL', 'XC', 'CD', 'CM') in addition to single characters. Maintain a map that includes these two-character combinations with their corresponding values. Iterate through the string, checking if a two-character combination exists in the map starting at the current index. If it does, add its value to the total and advance the index by two; otherwise, add the value of the single character at the current index and advance the index by one. This approach avoids out-of-bounds checks needed in approach 1. Time complexity: O(n), where n is the length of the Roman numeral string. Space complexity: O(1), as the map has a fixed size.",
            "Approach 3: Right-to-left pass. Iterate through the Roman numeral string from right to left. Maintain a map of Roman numeral characters to their integer values. Initialize the total with the value of the rightmost character. For each character from right to left (excluding the rightmost), compare its value with the value of the character to its right. If the current character's value is less than the value of the character to its right, subtract the current character's value from the total; otherwise, add it to the total. This approach simplifies the logic by avoiding special case handling for the end of the string and is mathematically equivalent to the other approaches. Time complexity: O(n), where n is the length of the Roman numeral string. Space complexity: O(1), as the map has a fixed size. This is the most elegant approach."
        ],
        "ques_num": 13
    },
    {
        "question": "Longest Common Prefix",
        "description": "Given an array of strings, find the longest common prefix among all strings present in the array.",
        "approaches": [
            "Approach 1: Horizontal Scanning. Iterate through the strings in the array, finding the longest common prefix (LCP) of the first two strings. Then, find the LCP of the result with the next string, and so on. This process continues until all strings have been processed. If at any point the LCP is an empty string, the algorithm terminates. The time complexity is O(S), where S is the sum of all characters in all strings. In the worst case, all strings are the same, leading to S character comparisons. The space complexity is O(1) as only constant extra space is used.",
            "Approach 2: Divide and Conquer. Recursively divide the array of strings into two halves, find the longest common prefix in each half, and then find the longest common prefix of the two resulting prefixes. The base case for the recursion is when the subarray contains only one string, in which case that string is the longest common prefix. The time complexity is O(S), where S is the total number of characters in the array. The space complexity is O(m * log n), where m is the length of the shortest string and n is the number of strings, due to the recursive calls on the execution stack.",
            "Approach 3: Binary Search. Find the minimum length string within the array. Perform a binary search on the possible lengths of the common prefix, from 0 to the length of the shortest string. For each mid value in the binary search, check if a prefix of that length is common to all strings. If it is, search for a longer prefix in the right half; otherwise, search in the left half. The time complexity is O(S * log m), where S is the sum of the characters in the array, and m is the length of the shortest string. The space complexity is O(1) as only constant extra space is used."
        ],
        "ques_num": 14
    },
    {
        "question": "3Sum",
        "description": "Given an array of integers, find all unique triplets (three numbers) that sum to zero.",
        "approaches": [
            "Approach 1: \"No-Sort\" Hashset Approach. Iterate through the array using nested loops. For each pair of elements (nums[i], nums[j]), calculate the complement needed to sum to zero. Use a hashset (dups) to skip duplicates in the outer loop. Also use a hashmap (seen) to avoid re-populating a hashset every time in the inner loop. Values in the hashmap will indicate whether we have encountered that element in the current iteration. Put a combination of three values into a hashset to avoid duplicates. Values in a combination should be ordered (e.g. ascending). Time complexity: O(n^2). Space complexity: O(n) for the hashset/hashmap, and potentially O(n^2) for storing the output.",
            "Approach 2: Hashset Approach. First, sort the input array. Then, iterate through the array. For each element nums[i], find pairs nums[j] and nums[k] to its right such that nums[i] + nums[j] + nums[k] = 0.  Use a hashset to implement a two-sum approach to find the pairs. In the two-sum function, compute the complement as -nums[i] - nums[j], and check if the complement exists in the hashset. If it does, add the triplet to the result. Skip duplicate values using a while loop. Time complexity: O(n^2) due to the nested loops and sorting. Space complexity: O(n) for the hashset.",
            "Approach 3: Two Pointers Approach. First, sort the input array. Then, iterate through the array. For each element nums[i], use two pointers, low and high, to find two elements nums[low] and nums[high] such that nums[i] + nums[low] + nums[high] = 0. Initialize low to i+1 and high to the end of the array. Move the pointers based on whether the sum is less than, greater than, or equal to zero. Skip duplicate values by incrementing low while nums[low] is equal to the previous value, and decrementing high while nums[high] is equal to the next value. Time complexity: O(n^2) due to the nested loops and sorting. Space complexity: O(1) if sorting is done in place, or O(n) otherwise."
        ],
        "ques_num": 15
    },
    {
        "question": "3Sum Closest",
        "description": "Given an array of integers `nums` and a target integer `target`, find three integers in `nums` such that their sum is closest to `target`. Return the sum of the three integers. It is assumed that there is exactly one solution.",
        "approaches": [
            "Approach 1: Brute Force. Iterate through all possible triplets of numbers in the input array, calculate the sum of each triplet, and keep track of the sum that is closest to the target. This involves three nested loops. Time complexity: O(n^3). Space complexity: O(1).",
            "Approach 2: Binary Search. Sort the input array. Then, iterate through all possible pairs of numbers using nested loops. For each pair, use binary search to find the number in the remaining part of the array that, when added to the pair, gives a sum closest to the target. Since we might not find the exact complement number, check the next higher and the previous lower values obtained from binary search and update the closest difference accordingly. Time complexity: O(n^2 log n). Space complexity: O(log n) to O(n) depending on the sorting algorithm.",
            "Approach 3: Two Pointers. Sort the input array. Iterate through the array. For each element `nums[i]`, use two pointers, `lo` and `hi`, to find the pair `nums[lo]` and `nums[hi]` such that `nums[i] + nums[lo] + nums[hi]` is closest to the target. Move the `lo` and `hi` pointers based on whether the current sum is less than or greater than the target. Keep track of the minimum difference found so far. Time complexity: O(n^2) due to the outer loop and the two pointers. Space complexity: O(log n) to O(n) depending on the sorting algorithm."
        ],
        "ques_num": 16
    },
    {
        "question": "Letter Combinations of a Phone Number",
        "description": "Given a string containing digits from 2-9 inclusive, return all possible letter combinations that the number could represent. A mapping of digit to letters (just like on the telephone buttons) is given. The input string's length is between 0 and 4.",
        "approaches": [
            "Approach 1: Brute-force generation. Generate all possible combinations of letters by iterating through each digit and its corresponding letters. This approach has no smart optimizations and simply explores all possibilities. Time complexity: O(4^N * N), where N is the length of the input digits string. Space complexity: O(4^N) for storing all combinations.",
            "Approach 2: Iterative approach using a queue. Initialize a queue with an empty string. Iterate through the digits. For each digit, iterate through its corresponding letters. For each letter, append it to each string in the queue and add the new strings back to the queue. After processing all digits, the queue will contain all the combinations. Time complexity: O(4^N * N), where N is the length of the input digits string. Space complexity: O(4^N) for storing all combinations in the queue.",
            "Approach 3: Backtracking (Recursion). Use a recursive function to explore all possible letter combinations. The function takes the current index of the digits string and the current combination string as input. If the index reaches the end of the digits string, add the current combination to the result. Otherwise, iterate through the letters corresponding to the current digit, append each letter to the current combination, and recursively call the function with the next index. After the recursive call, remove the letter (backtrack) to explore other combinations. Time complexity: O(4^N * N), where N is the length of the input digits string. Space complexity: O(N) due to the recursion call stack (depth of recursion is N). This is the most optimal approach considering it is the most readable and efficient in terms of space complexity for this problem."
        ],
        "ques_num": 17
    },
    {
        "question": "4Sum",
        "description": "Given an array of integers `nums` and an integer `target`, find all unique quadruplets `[nums[a], nums[b], nums[c], nums[d]]` such that `a`, `b`, `c`, and `d` are distinct and `nums[a] + nums[b] + nums[c] + nums[d] == target`. Generalize this problem to k-Sum, where you need to find k numbers that sum up to the target.",
        "approaches": [
            "Approach 1: Brute-Force. This involves iterating through all possible combinations of four numbers using four nested loops. For each combination, check if the sum equals the target. To avoid duplicates, store the quadruplets in a set after sorting them. This approach is simple to understand but highly inefficient. The time complexity is O(n^4) due to the four nested loops, and the space complexity is O(m), where m is the number of unique quadruplets found, to store the result in a set.",
            "Approach 2: Using a Hash Map (for Two Sum within a Recursive k-Sum). Sort the array first. Then, implement k-Sum recursively. In the base case (k=2), use a hash map to find pairs that sum to the remaining target. For k>2, iterate through the array, recursively call kSum with a reduced target and k value. The time complexity is O(n^(k-1)), as there are k-2 nested loops and twoSum using Hashmap takes O(n). The space complexity is O(n) for the hash map and O(k) for recursion depth.",
            "Approach 3: Two Pointers with Recursion. Sort the input array. Implement kSum recursively. If k equals 2, use the two-pointer technique to find pairs that sum to the target. For k > 2, iterate through the array, recursively call kSum with the remaining target and k-1. Skip duplicate values to avoid duplicate quadruplets. This approach has a time complexity of O(n^(k-1)) because there are k-2 loops and the two-pointer approach takes O(n) time. The space complexity is O(n), as sorting takes O(n) space and the recursion stack can grow to O(k), where k can be same as n in worst case."
        ],
        "ques_num": 18
    },
    {
        "question": "Remove Nth Node From End of List",
        "description": "Given the head of a linked list, remove the nth node from the end of the list and return its head.",
        "approaches": [
            "Approach 1: Convert to Array. Convert the linked list to an array. Remove the element at index (length of array - n). Reconstruct the linked list from the array. Time Complexity: O(N) for conversion and reconstruction. Space Complexity: O(N) for the array.",
            "Approach 2: Two-Pass Algorithm. First, traverse the linked list to find its length, L. Then, traverse the list again to find the (L - n + 1)-th node from the beginning and remove it. A dummy node simplifies edge cases. Time Complexity: O(L) because it involves two traversals of the list. Space Complexity: O(1) because it uses constant extra space.",
            "Approach 3: One-Pass Algorithm using Two Pointers. Use two pointers, 'first' and 'second'. Advance 'first' n+1 nodes ahead. Then, move both pointers simultaneously until 'first' reaches the end. 'Second' will now be pointing to the node before the one to be deleted. Relink second's next pointer to skip the nth node from the end. A dummy node handles edge cases. Time complexity: O(L) because it involves one traversal of the list. Space complexity: O(1) because it uses constant extra space, making it the optimal approach."
        ],
        "ques_num": 19
    },
    {
        "question": "Valid Parentheses",
        "description": "Given a string consisting of opening and closing parentheses ('(', ')', '{', '}', '[', ']'), determine if the string is valid. A string is valid if:\n\n1.  Open brackets must be closed by the same type of brackets.\n2.  Open brackets must be closed in the correct order.\n3.  Every close bracket has a corresponding open bracket of the same type.",
        "approaches": [
            "Approach 1: Using multiple counters. Maintain separate counters for each type of parenthesis. Increment the counter when an opening parenthesis is encountered and decrement when a closing parenthesis is encountered. Check if all counters are zero at the end. This approach doesn't work because the relative placement of the parenthesis matters. For example, '[}' would be considered valid. Time complexity: O(n), Space complexity: O(1)",
            "Approach 2: Iterative removal of matching pairs. Repeatedly search and remove matching pairs of parentheses ('()', '[]', '{}') from the string. If the string becomes empty after the removals, the original string is valid. The algorithm iterates through the string until no more matching pairs can be removed. If the string is empty at the end, the expression is valid; otherwise, it is invalid. Time complexity: O(n^2) in the worst case, where n is the length of the string. This is due to repeated searching and string modifications. Space complexity: O(1) if modifications are done in-place, O(n) otherwise.",
            "Approach 3: Using a stack. Iterate through the string. If an opening parenthesis is encountered, push it onto the stack. If a closing parenthesis is encountered, check if the stack is empty or if the top element of the stack is not the corresponding opening parenthesis. If either of these conditions is true, the string is invalid. Otherwise, pop the top element from the stack. After processing the entire string, if the stack is empty, the string is valid; otherwise, it is invalid. Time complexity: O(n), where n is the length of the string, as each character is processed once. Space complexity: O(n) in the worst case, where all characters are opening parentheses."
        ],
        "ques_num": 20
    },
    {
        "question": "Merge Two Sorted Lists",
        "description": "Merge two sorted linked lists and return it as a sorted list. The list should be made by splicing together the nodes of the first two lists.",
        "approaches": [
            "Approach 1: Convert both linked lists into arrays, merge the arrays, sort the merged array, and then create a new linked list from the sorted array. This approach has a time complexity of O((n+m)log(n+m)) due to the sorting step and a space complexity of O(n+m) to store the merged array. It is relatively straightforward to implement but inefficient due to the unnecessary sorting step.",
            "Approach 2: Iterative merging using a dummy head. Create a dummy head node and a 'tail' pointer. Iterate through both lists, comparing the current nodes' values. Append the smaller node to the 'tail' and advance either list1 or list2. After one list is exhausted, append the remaining nodes from the other list to the 'tail'. Return the next of the dummy head. This approach offers O(n+m) time complexity because each node is visited only once, and O(1) space complexity because it only uses a few extra pointers.",
            "Approach 3: Recursive merging. Compare the heads of the two lists. The smaller head becomes the head of the merged list. Recursively merge the rest of that list with the other list. If either list is null, return the other list. This approach has a time complexity of O(n+m) because each node is visited once, but a space complexity of O(n+m) due to the recursive call stack. While it has the same time complexity as the iterative approach, the iterative approach is generally preferred due to its constant space complexity."
        ],
        "ques_num": 21
    },
    {
        "question": "Generate Parentheses",
        "description": "Given an integer 'n', generate all possible well-formed (balanced) combinations of parentheses of length '2n'.",
        "approaches": [
            "Approach 1: Brute Force. Generate all possible strings of length 2n using '(' and ')'. Then, for each string, check if it is a valid parentheses combination. A valid combination has the same number of opening and closing parentheses, and for every prefix, the number of opening parentheses is greater than or equal to the number of closing parentheses. The time complexity is O(2^(2n) * n) because there are 2^(2n) possible strings, and checking each string takes O(n) time. The space complexity is O(2^(2n)) to store all possible strings. This approach is inefficient because it generates many invalid strings.",
            "Approach 2: Backtracking. Use backtracking to generate only valid parentheses combinations. Maintain two counters, 'left' and 'right', representing the number of opening and closing parentheses used so far. Recursively build the string by adding either '(' or ')' based on the following conditions: add '(' if left < n, and add ')' if right < left. The base case is when the length of the string is 2n, at which point it is a valid combination. The time complexity is O(C_n) where C_n is the nth Catalan number, which is approximately O(4^n / n^(3/2)). The space complexity is O(n) due to the recursive call stack. This approach is significantly better than brute force because it avoids generating invalid combinations.",
            "Approach 3: Divide and Conquer. Decompose the problem of generating all well-formed parenthesis strings of length 2n into smaller subproblems of generating valid strings of smaller lengths. The approach involves constructing F(n) by concatenating a valid string of length 'i', generated by F(i), with a valid string of length 'n - i - 1', generated by F(n-i-1), all enclosed by a pair of parenthesis, denoted as '(' + F(i) + ')' + F(n-i-1). The time complexity is O(C_n) where C_n is the nth Catalan number, which is approximately O(4^n / n^(3/2)). The space complexity is O(n) due to the recursive call stack. This approach generates only valid combinations, it can involve repetitive calculations if not optimized with memoization. Backtracking is generally preferred due to its simpler implementation and comparable complexity."
        ],
        "ques_num": 22
    },
    {
        "question": "Merge k Sorted Lists",
        "description": "You are given k sorted linked lists, and the task is to merge them into one sorted linked list.",
        "approaches": [
            "Approach 1: Brute Force. Traverse all linked lists and collect all node values into an array. Sort the array. Create a new linked list and extend it with the sorted values from the array. The time complexity is O(N log N), where N is the total number of nodes. This is because collecting the values takes O(N) time, sorting takes O(N log N) time, and creating the new linked list takes O(N) time. The space complexity is O(N), due to the array and the new linked list.",
            "Approach 2: Compare One by One. Compare the head nodes of every k linked lists to find the smallest value. Extend the final sorted linked list with this smallest node. Repeat until all lists are exhausted. The time complexity is O(kN), where k is the number of linked lists and N is the total number of nodes. This is because each selection of a node involves comparing k nodes. The space complexity is O(n) for creating new linked list and O(1) if done in place.",
            "Approach 3: Optimize Approach 2 by Priority Queue. Use a priority queue (min-heap) to store the head nodes of the k linked lists. The priority queue automatically keeps the smallest node at the top. Extract the smallest node, add it to the merged list, and insert the next node from the corresponding list into the priority queue. The time complexity is O(N log k), where N is the total number of nodes and k is the number of linked lists. Each insertion and extraction from the priority queue takes O(log k) time, and we perform these operations for each of the N nodes. The space complexity is O(k) for the priority queue."
        ],
        "ques_num": 23
    },
    {
        "question": "Swap Nodes in Pairs",
        "description": "Given the head of a singly linked list, swap every two adjacent nodes and return the head of the modified list. You must solve the problem without modifying the values in the list's nodes (i.e., only nodes themselves may be changed).",
        "approaches": [
            "Approach 1: Brute-Force using an array. Traverse the linked list and store the node values in an array. Then, swap the elements in the array in pairs. Finally, create a new linked list with the swapped values from the array. This approach modifies the values in the list, violating the problem constraints. Time complexity is O(N) for traversal and array manipulation, and space complexity is O(N) for the array.",
            "Approach 2: Recursive Approach. Start the recursion with the head of the original linked list. Each recursive call swaps a pair of nodes (firstNode and secondNode). The next recursion is made by calling the function with the head of the next pair of nodes. Once the remaining swapped list is returned from the recursion call, swap the firstNode and secondNode in the current recursive call and return the pointer to the secondNode (new head after swapping). The base cases are when the list is empty or has only one node. Time complexity is O(N) and space complexity is O(N) due to the stack space utilized for recursion.",
            "Approach 3: Iterative Approach. Iterate through the linked list, swapping nodes in pairs. Use a 'prevNode' to keep track of the node before the current pair being swapped, allowing the correct linking of swapped pairs. Create a dummy node to handle the case where the head needs to be changed. Time complexity is O(N), as it iterates through the list once. Space complexity is O(1), as it only uses a constant amount of extra space."
        ],
        "ques_num": 24
    },
    {
        "question": "Reverse Nodes in k-Group",
        "description": "Given a singly linked list, reverse the nodes of the list k at a time and return the modified list. k is a positive integer and is less than or equal to the length of the linked list. If the number of nodes is not a multiple of k then left-out nodes, in the end, should remain as they are.",
        "approaches": [
            "Approach 1: Recursion. Use recursion to reverse k nodes at a time. First, count k nodes in the list. If there are fewer than k nodes, return the head. Otherwise, reverse the first k nodes. Recursively call the function on the remaining list and connect the reversed k nodes to the result of the recursive call. Time complexity: O(N) since we process each node exactly twice (once while counting and once while reversing). Space complexity: O(K) due to the recursion stack, where K is the number of nodes to be reversed.",
            "Approach 2: Iterative O(1) space. Maintain four pointers: head (points to the original head of the next set of k nodes), revHead (basically the tail node of the original set of k nodes, hence becomes the new head after reverse), kTail (is the tail node of the previous set of k nodes after reversal), and newHead (acts as the head of the final list that we need to return as the output). Iterate through the list, reversing k nodes at a time. Connect the reversed k nodes to the previous group of reversed nodes. Time Complexity: O(N) since we process each node exactly twice (once when we are counting the number of nodes in each iterative call, and then once when we are actually reversing the sub-list.). Space Complexity: O(1).",
            "Approach 3: Iterative in-place reversal using a constant number of pointers. Iterate through the linked list, reversing k nodes at a time. Use three pointers: `prev`, `curr`, and `next`. Reverse the links of the first k nodes. Connect the reversed k-node sublist to the previous and next parts of the list. Repeat until the end of the list. Time complexity: O(N), where N is the number of nodes in the linked list. Each node is visited and reversed at most once. Space complexity: O(1), as the reversal is done in-place using a constant number of pointers."
        ],
        "ques_num": 25
    },
    {
        "question": "Remove Duplicates from Sorted Array",
        "description": "Given an integer array `nums` sorted in non-decreasing order, remove the duplicates in-place such that each unique element appears only once. The relative order of the elements should be kept the same. The result should be placed in the first part of the array `nums`. Return the number of unique elements `k` after placing the final result in the first `k` slots of `nums`. Do not allocate extra space for another array. You must do this by modifying the input array in-place with O(1) extra memory.",
        "approaches": [
            "Approach 1: Brute Force with Extra Space. Create a new array and iterate through the input array. Add each unique element to the new array. Finally, copy the elements from the new array back to the input array. This approach has a time complexity of O(N) due to the iteration and copying, and a space complexity of O(N) because of the extra array. This violates the in-place requirement.",
            "Approach 2: Two Pointers (with modification). Maintain two pointers, `i` and `j`. `i` points to the next position to write a unique element, and `j` iterates through the array. If `nums[i-1]` != `nums[j]`, then copy `nums[j]` to `nums[i]` and increment `i`. This approach has a time complexity of O(N) because both pointers traverse the array at most once. The space complexity is O(1) as it's an in-place modification. The minor modification is to start the `insertIndex` from 1, and the `i` from 1.",
            "Approach 3: Optimized Two Pointers. This is the same as approach 2, but slightly cleaner. Initialize `insertIndex = 1`, and iterate `i` from 1 to `nums.size()`. Compare `nums[i]` with `nums[i-1]`. If they are different, then assign `nums[insertIndex] = nums[i]` and increment `insertIndex`. This leverages the sorted nature of the array. The time complexity is O(N), and the space complexity is O(1). This is the optimal approach as it solves the problem in-place with a single pass."
        ],
        "ques_num": 26
    },
    {
        "question": "Remove Element",
        "description": "Given an integer array `nums` and an integer `val`, remove all occurrences of `val` in `nums` in-place. Return the number of elements remaining in the array after removing all occurrences of `val`.",
        "approaches": [
            "Approach 1: Brute Force. Iterate through the array. If an element equals `val`, shift all subsequent elements one position to the left, effectively removing the element. Repeat until all occurrences are removed. This approach modifies the array in-place. The time complexity is O(n^2) in the worst case where `val` appears frequently, due to the shifting of elements, and the space complexity is O(1) as it is an in-place operation.",
            "Approach 2: Two Pointers (Slow-Fast Runner). Use two pointers, `i` (slow runner) and `j` (fast runner). Iterate through the array with `j`. If `nums[j]` is not equal to `val`, copy `nums[j]` to `nums[i]` and increment both `i` and `j`. If `nums[j]` is equal to `val`, increment `j` to skip the element. After the loop, `i` will be the new length of the array. This approach modifies the array in-place. The time complexity is O(n) because both pointers traverse the array at most once, and the space complexity is O(1) because it's an in-place operation.",
            "Approach 3: Two Pointers (Swap and Reduce). Use two pointers, `i` starting from the beginning and `n` starting from the end of the array. Iterate while `i < n`. If `nums[i]` equals `val`, swap `nums[i]` with `nums[n-1]` and decrement `n`. This effectively replaces the element to be removed with an element from the end of the array. If `nums[i]` is not equal to `val`, increment `i`. The final value of `n` will be the new length of the array. This approach is particularly efficient when elements to remove are rare, as it minimizes unnecessary element movements. The time complexity is O(n) and space complexity is O(1)."
        ],
        "ques_num": 27
    },
    {
        "question": "Substring with Concatenation of All Words",
        "description": "You are given a string s and an array of strings words. All the strings of words are of the same length. A concatenated substring is a substring that is a concatenation of each element of words exactly once and without any intervening characters. Return a list of all starting indices of concatenated substrings in s.",
        "approaches": [
            "Approach 1: Check all indices using a hash table. Iterate through the string s, and for each index, check if a valid substring starts at that index. A valid substring is a concatenation of all words in the `words` array exactly once and without any intervening characters. Use a hash table to store the counts of each word in the `words` array. For each index in `s`, create a copy of the hash table and iterate through the substring of length `wordLength * words.length`, checking if the words exist in the hash table and decrementing the count. If all words are found, the substring is valid. The time complexity is O(n * m * k), where n is the length of `s`, m is the length of `words`, and k is the length of each word. The space complexity is O(m), where m is the length of `words`.",
            "Approach 2: Sliding Window. Use a sliding window of size `wordLength * words.length` to iterate through the string `s`. Maintain a hash table to store the counts of each word in the `words` array and another hash table to track the words in the current window. When the right bound of the window moves, check if the new word is in the `words` array. If it is, update the window's hash table. If the count of a word in the window exceeds its count in the `words` array, move the left bound until the excess word is removed. If all words in the `words` array are present in the window with the correct counts, add the starting index of the window to the result. The time complexity is O(n * k), where n is the length of `s`, and k is the length of each word. The space complexity is O(m), where m is the length of `words`.",
            "Approach 3: Optimized Sliding Window with Fixed Increments. The sliding window approach can be optimized further by avoiding duplicate computations. Instead of sliding the window one character at a time, slide the window by `wordLength` at a time. This is possible because all words have the same length. For each starting index from 0 to `wordLength - 1`, apply the sliding window technique as described in Approach 2. The overall time complexity becomes O(n), where n is the length of `s` and the space complexity is O(m) where m is the number of words. This is better than previous approaches as it reduces redundant computations and optimizes the traversal of the string."
        ],
        "ques_num": 30
    },
    {
        "question": "Next Permutation",
        "description": "Given an array of integers, find the next lexicographically greater permutation of the array. If no such greater permutation exists, rearrange the array in ascending order.",
        "approaches": [
            "Approach 1: Brute Force. Generate all possible permutations of the input array. Then, iterate through the generated permutations and find the one that is just larger than the given input array. If no such permutation exists, sort the array in ascending order. This approach has a time complexity of O(n!) because there are n! possible permutations, and a space complexity of O(n) to store the permutations. This approach is not efficient for larger arrays due to its factorial time complexity.",
            "Approach 2: Single Pass Approach using the algorithm outlined in the image. First, find the first decreasing element from the right. Then, find the element just larger than it on the right side and swap them. Finally, reverse the array to the right of the first element. The time complexity is O(n) and the space complexity is O(1).",
            "Approach 3: Optimized Single Pass Approach. This approach further refines the single-pass solution to minimize operations. Similar to Approach 2, it identifies the first decreasing element from the right (index `i`). If found, it locates the smallest element to the right of `i` that is greater than the element at `i` (index `j`). It swaps the elements at `i` and `j`, and then reverses the subarray to the right of `i`. If no decreasing element is found, the entire array is reversed. This optimized version maintains O(n) time complexity and O(1) space complexity, ensuring the fewest possible operations within the single pass."
        ],
        "ques_num": 31
    },
    {
        "question": "Longest Valid Parentheses",
        "description": "Given a string containing just the characters '(' and ')', find the length of the longest valid (well-formed) parentheses substring.",
        "approaches": [
            "Approach 1: Brute Force. Consider every possible non-empty even length substring from the given string and check whether it's a valid string of parentheses or not using a stack. For every '(' push it onto the stack. For every ')' encountered, pop a '(' from the stack. If the stack is empty or contains elements after processing the complete substring, the substring is invalid. Repeat the process for every possible substring and keep track of the length of the longest valid string found so far. Time complexity: O(n^3) because generating every possible substring from a string of length n requires O(n^2) and checking validity of a string of length n requires O(n). Space complexity: O(n) because a stack of depth n will be required for the longest substring.",
            "Approach 2: Dynamic Programming. Use a dp array where dp[i] represents the length of the longest valid substring ending at index i. Initialize the complete dp array with 0's. Valid substrings must end with ')'. Update the dp array only when ')' is encountered. If s[i] = ')' and s[i-1] = '(', then dp[i] = dp[i-2] + 2. If s[i] = ')' and s[i-1] = ')', and also s[i - dp[i-1] - 1] = '(', then dp[i] = dp[i-1] + dp[i - dp[i-1] - 2] + 2. Time complexity: O(n) because a single traversal of the string is done to fill the dp array. Space complexity: O(n) because a dp array of size n is used.",
            "Approach 3: Using Stack. Instead of checking every possible string, use a stack while scanning the string. Push -1 onto the stack initially. For every '(' encountered, push its index onto the stack. For every ')' encountered, pop the topmost element. Then, the length of the currently encountered valid string of parentheses will be the difference between the current element's index and the top element of the stack. If, while popping the element, the stack becomes empty, push the current element's index onto the stack. In this way, we can continue to calculate the length of the valid substrings and return the length of the longest valid string at the end. Time complexity: O(n), where n is the length of the given string. Space complexity: O(n), as the size of the stack can go up to n.",
            "Approach 4: Without extra space. Use two counters, left and right. First, traverse the string from left to right, incrementing 'left' for '(' and 'right' for ')'. Whenever left becomes equal to right, calculate the length of the current valid string and keep track of the maximum length substring found so far. If right becomes greater than left, reset left and right to 0. Next, traverse the string from right to left using a similar procedure. Time complexity: O(n) because two traversals of the string are needed. Space complexity: O(1) because only two extra variables (left and right) are needed."
        ],
        "ques_num": 32
    },
    {
        "question": "Search in Rotated Sorted Array",
        "description": "Given a rotated sorted array, search for a target element in it. The array is sorted but rotated at an unknown pivot. Find the index of the target element if it exists in the array, otherwise return -1. The goal is to achieve a search in O(log N) time.",
        "approaches": [
            "Approach 1: Linear Search. Iterate through the entire array and compare each element with the target. If the target is found, return its index. If the target is not found after iterating through the entire array, return -1. This approach has a time complexity of O(N) and a space complexity of O(1). This is inefficient for large arrays due to the linear time complexity, and does not leverage the sorted nature of the array.",
            "Approach 2: Binary Search with Rotation Index. First, find the index of the smallest element (rotation index) using binary search. Then, compare the target with the first element of the array to determine which half of the array the target might be in. Finally, perform a standard binary search in the appropriate half. Finding the rotation index takes O(log N) time, and the binary search also takes O(log N) time, resulting in a total time complexity of O(log N). The space complexity is O(1). This is better than linear search but requires two passes through the array.",
            "Approach 3: One-Pass Binary Search. Perform a modified binary search that takes into account the rotation. In each iteration, determine which half of the array is sorted and then check if the target lies within that sorted half. If it does, continue the binary search in that half; otherwise, continue the binary search in the other half. This approach achieves O(log N) time complexity with O(1) space complexity, combining the rotation index finding and searching into a single pass, making it the most efficient solution."
        ],
        "ques_num": 33
    },
    {
        "question": "Find First and Last Position of Element in Sorted Array",
        "description": "Given a sorted array of integers, find the starting and ending position of a given target value. If the target is not found in the array, return [-1, -1].",
        "approaches": [
            "Approach 1: Linear Scan. Iterate through the array and record the first and last occurrences of the target value. This approach doesn't leverage the sorted property of the array. The time complexity is O(N) in the worst case (when all elements are the target value), and the space complexity is O(1).",
            "Approach 2: Binary Search and Bidirectional Scan. First, use binary search to find any occurrence of the target. Then, perform a linear scan to the left and right from that occurrence to find the first and last positions, respectively. While it utilizes binary search, the linear scans in both directions can still lead to O(N) time complexity in the worst-case scenario where the target occupies a large portion of the array. The space complexity remains O(1).",
            "Approach 3: Two Binary Searches. Use binary search twice: once to find the first occurrence and once to find the last occurrence. To find the first occurrence, modify the binary search to continue searching in the left subarray even when the target is found, until the first occurrence is located. Similarly, to find the last occurrence, modify the binary search to continue searching in the right subarray. This approach fully leverages the sorted nature of the array, resulting in a time complexity of O(log N) for each binary search, totaling O(log N). The space complexity is O(1)."
        ],
        "ques_num": 34
    },
    {
        "question": "Search Insert Position",
        "description": "Given a sorted array of integers, find the index of a target value. If the target is not found, return the index where it would be inserted to maintain the sorted order.",
        "approaches": [
            "Approach 1: Linear Search. Iterate through the array, comparing each element with the target. If the target is found, return the index. If the target is smaller than the current element, return the current index (as that's where it should be inserted). If the target is larger than all elements, return the length of the array. This approach has a time complexity of O(n) in the worst case (target is larger than all elements or not present at all) and a space complexity of O(1).",
            "Approach 2: Binary Search with Integer Overflow Prevention. Implement binary search to find the target's index. Initialize `left` to 0 and `right` to `n-1`. In each iteration, calculate the middle index `pivot` as `left + (right - left) / 2` to prevent integer overflow. Compare `nums[pivot]` with the target. Adjust `left` or `right` accordingly. If the target is not found, return `left`. The time complexity is O(log n), and the space complexity is O(1).",
            "Approach 3: Binary Search with Bitwise Operations for Integer Overflow Prevention. Similar to approach 2, implement binary search to find the target's index. Initialize `left` to 0 and `right` to `n-1`. In each iteration, calculate the middle index `pivot` as `(unsigned int)(left + right) >> 1` to prevent integer overflow using bitwise operations. Compare `nums[pivot]` with the target. Adjust `left` or `right` accordingly. If the target is not found, return `left`. The time complexity is O(log n), and the space complexity is O(1). This approach can be slightly faster than using subtraction and division for calculating the pivot."
        ],
        "ques_num": 35
    },
    {
        "question": "Valid Sudoku",
        "description": "Given a partially filled 9x9 Sudoku board, determine whether it is valid according to Sudoku rules. A valid Sudoku board should satisfy three conditions: each row must contain the digits 1-9 without repetition, each column must contain the digits 1-9 without repetition, and each of the nine 3x3 sub-boxes of the grid must contain the digits 1-9 without repetition.",
        "approaches": [
            "Approach 1: Brute-force approach using nested loops and repeated linear searches. Iterate through each row, column, and 3x3 subgrid, and for each cell, search the rest of that row/column/subgrid to check for duplicates. This method involves no additional data structures. The time complexity is O(N^3), where N is the size of the board (9 in this case), due to the nested loops for iteration and the linear searches within each row, column, and subgrid. The space complexity is O(1) as no extra space is used.",
            "Approach 2: Using arrays of fixed length to track occurrences. Initialize an array of size 9 for each row, column, and box to represent whether a number has been seen. When iterating over the board, check if the number has already been seen in the corresponding row, column or box by checking the value in the array. If the number has already been seen, then the board is invalid. Otherwise, update the value in the array. The time complexity is O(N^2), where N is the size of the board (9 in this case) because we need to traverse every position in the board. The space complexity is O(N^2) because we need to create 3N arrays each with size N to store all previously seen numbers for all N rows, columns, and boxes.",
            "Approach 3: Using bit manipulation to track occurrences. Use an integer to represent each row, column, and box, where each bit corresponds to a number from 1 to 9. Iterate through the board, and for each number, check if the corresponding bit is already set in the row, column, and box integers. If it is, the Sudoku is invalid. Otherwise, set the bit. This approach is efficient because bitwise operations are fast. The time complexity is O(N^2) because we need to traverse every position in the board. The space complexity is O(N) because we need N binary numbers to store all seen numbers in all rows, columns, and boxes. This is the most space-efficient method and improves upon Approach 2 by using bits instead of integers, leading to reduced space usage."
        ],
        "ques_num": 36
    },
    {
        "question": "Sudoku Solver",
        "description": "Given a partially filled 9x9 Sudoku grid, the goal is to fill the remaining cells such that each row, each column, and each of the nine 3x3 subgrids contains all of the digits from 1 to 9. Find a valid solution to the Sudoku puzzle.",
        "approaches": [
            "Approach 1: Brute Force. Generate all possible combinations of numbers from 1 to 9 for the empty cells and check if each combination satisfies the Sudoku rules. This involves filling the first empty cell with a number from 1 to 9, then the second, and so on. After filling all empty cells, check if the solution is valid. If not, try the next combination. This approach has a very high time complexity, approximately O(9^m) where 'm' is the number of empty cells. The space complexity is O(1) as we are modifying the existing board in place. This approach is extremely slow and impractical for most Sudoku puzzles.",
            "Approach 2: Backtracking without Constraint Propagation. Implement a recursive backtracking algorithm. Iterate through each empty cell. For each empty cell, try numbers from 1 to 9. If a number is valid according to Sudoku rules (not present in the same row, column, or 3x3 subgrid), place the number and recursively call the backtracking function for the next empty cell. If the recursive call returns a solution, return true. If no number is valid or the recursive call fails, backtrack by resetting the cell to empty and try the next number. Time complexity is significantly better than brute force but still exponential in the worst case. Space complexity is O(n), where n is the depth of recursion, at most 81.",
            "Approach 3: Backtracking with Constraint Propagation. This is the most efficient approach. Use the backtracking algorithm from Approach 2, but add constraint propagation. Before placing a number in a cell, check if placing that number will violate any constraints in the row, column, and 3x3 subgrid. Use auxiliary arrays (or bitsets) to keep track of which numbers are already present in each row, column, and subgrid. This significantly reduces the search space by eliminating invalid numbers early on. The time complexity is difficult to express precisely but is significantly better than the previous approaches and can solve most Sudoku puzzles efficiently in near-linear time. Space complexity includes the space for the board and the auxiliary arrays/bitsets to track constraints, which is O(1) since it's a fixed size 9x9 grid."
        ],
        "ques_num": 37
    },
    {
        "question": "Count and Say",
        "description": "The problem requires generating the n-th term of the count-and-say sequence. The count-and-say sequence is generated iteratively. Start with \"1\". The next term is generated by 'saying' the previous term, which involves counting consecutive identical digits and appending the count and the digit to the result.",
        "approaches": [
            "Approach 1: Straightforward Iteration. This approach iteratively generates each term of the sequence from 1 to n. For each term, it iterates through the string, counts consecutive identical digits, and appends the count and the digit to the next term. This process is repeated until the n-th term is generated. The time complexity is O(4^(n/3)) and the space complexity is O(4^(n/3)), since the length of the string grows exponentially.",
            "Approach 2: Regular Expression Matching. This approach utilizes regular expressions to identify consecutive groups of identical digits in the string. The regex pattern '(.)\\1*' is used to match one or more occurrences of any character. After finding each match, the length of the matched substring (count) and the character itself are appended to the next term. This approach has the same O(4^(n/3)) time and space complexity as the previous one, since the regex matching is linear in the input string length.",
            "Approach 3: (Hypothetical - Since the provided document only contains two approaches) Dynamic Programming with Memoization. While not explicitly present in the image, a hypothetical DP approach could memoize previously computed count-and-say strings. This would avoid recomputation for smaller values of 'n'. The time complexity would still be bounded by the length of the strings generated, however the memoization could offer some practical performance improvements in scenarios where intermediate results are frequently reused. The space complexity would remain O(4^(n/3))."
        ],
        "ques_num": 38
    },
    {
        "question": "Combination Sum",
        "description": "Given a set of candidate numbers (candidates) and a target number (target), find all unique combinations in candidates where the candidate numbers sum to target. The same repeated number may be chosen from candidates unlimited number of times. Two combinations are unique if the frequency of at least one of the chosen numbers is different.",
        "approaches": [
            "Approach 1: Brute-force. Generate all possible combinations of candidates with repetition and check if their sum equals the target. This involves generating combinations of varying lengths and summing them up. Time complexity is exponential, roughly O(N^(T/M)), where N is the number of candidates, T is the target, and M is the minimum value in candidates, due to the many combinations generated. Space complexity is also exponential, O(N^(T/M)), to store the combinations. This approach is highly inefficient and impractical for larger inputs due to the excessive number of combinations generated and checked.",
            "Approach 2: Backtracking with pruning. Use a recursive backtracking approach to explore possible combinations. At each step, add a candidate number to the current combination and recursively call the function with the updated remaining target. If the target becomes zero, add the combination to the result. If the target becomes negative, backtrack. To avoid duplicate combinations, maintain a start index and only consider candidates from that index onward. The time complexity is O(N^(T/M)), where N is the number of candidates, T is the target, and M is the minimal value among the candidates. The space complexity is O(T/M) due to the recursive call stack.",
            "Approach 3: Backtracking with Sorting and Pruning. Sort the candidates array to efficiently prune redundant branches. During backtracking, skip duplicate candidate numbers to avoid generating duplicate combinations. If the current candidate is greater than the remaining target, stop exploring that branch. This optimization significantly reduces the number of unnecessary recursive calls. The time complexity remains O(N^(T/M)) in the worst case, but in practice, it performs much better due to the effective pruning. The space complexity is O(T/M) due to the recursive call stack, plus O(N) for sorting the candidates."
        ],
        "ques_num": 39
    },
    {
        "question": "Combination Sum II",
        "description": "Given a list of candidate numbers (candidates) and a target number (target), find all unique combinations in candidates where the candidate numbers sum to target. Each number in candidates may only be used once in each combination. Note that the input list `candidates` may contain duplicate numbers, and the solution should not contain duplicate combinations.",
        "approaches": [
            "Approach 1: Backtracking without handling duplicates. A naive backtracking approach would iterate through the `candidates` array and recursively explore combinations. However, this approach will generate duplicate combinations if the input array contains duplicate numbers. To avoid infinite recursion, the algorithm stops exploring when the sum equals or exceeds the target. Time complexity is O(2^N) and space complexity is O(N), where N is the number of candidates.",
            "Approach 2: Backtracking with Index. This approach sorts the input array and uses an index to avoid generating duplicate combinations. The algorithm iterates through the sorted input array, and for each number, it either includes it in the current combination or skips it. To avoid duplicates, the algorithm skips the current number if it's the same as the previous number in the sorted array and the index is not the start index. Additionally, early stopping is implemented to improve performance, by stopping the exploration if the sum of the current combination exceeds the target. The time complexity is O(2^N), dominated by backtracking, but the sorting step takes O(N log N). Space complexity is O(N).",
            "Approach 3: Backtracking with Counters. This approach first builds a counter table to store the frequency of each unique number in the input array. Then, it uses backtracking to explore combinations based on the counter table. This avoids generating duplicate combinations since it considers groups of unique numbers as candidates. The time complexity is O(2^N), where N is the size of the input array, as the algorithm exhausts all possible combinations. The space complexity is O(N) to store the counter table, the current combination, and the call stack."
        ],
        "ques_num": 40
    },
    {
        "question": "First Missing Positive",
        "description": "Given an unsorted integer array, find the smallest missing positive integer. The solution should run in O(n) time and use constant extra space, if possible.",
        "approaches": [
            "Approach 1: Using a hash map. Iterate through the array and store each positive number encountered in a hash map. Then, iterate from 1 to n+1 (where n is the array length) and check if each number exists in the hash map. The first missing number is the answer. This approach has a time complexity of O(n) and a space complexity of O(n) because of the hash map.",
            "Approach 2: Using a string as a hash map. Create a string of n '0' characters. Iterate through the array. If a number 'i' is found in the array, change the i-th character of the string to '1'. After iterating through the array, find the index of the first '0' in the string. The index + 1 is the first missing positive number. This solution has O(n) time complexity. Although it seems to use O(1) space, string manipulation can be costly if the array length is very large, and the string can take substantial memory.",
            "Approach 3: In-place modification of the input array. First, check if '1' is present in the array. If not, '1' is the answer. Replace negative numbers, zeros, and numbers larger than n by 1s. Iterate through the array. If you meet a number a in the array, change the sign of the a-th element. Be careful with duplicates. Use index a to save information about the presence of number a, since index n is not available. Iterate again along the array. Return the index of the first positive element. If you didn't find the positive element, that means that the answer is n + 1. This approach has a time complexity of O(n) because it involves multiple passes through the array. The space complexity is O(1) because it modifies the array in-place."
        ],
        "ques_num": 41
    },
    {
        "question": "Trapping Rain Water",
        "description": "Given an array of non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it can trap after raining.",
        "approaches": [
            "Approach 1: Brute Force. For each element in the array, find the maximum height of the bar to the left and the maximum height to the right. The water trapped at that index is the minimum of these two maximum heights minus the height of the current bar. Sum the trapped water for each index. Time complexity: O(n^2) because for each element, we iterate through the left and right parts of the array. Space complexity: O(1) as no extra space is used.",
            "Approach 2: Dynamic Programming. Create two arrays, `left_max` and `right_max`, to store the maximum height of the bar to the left and right of each index, respectively. Populate these arrays in O(n) time. Then, iterate through the height array and calculate the trapped water at each index using the precomputed `left_max` and `right_max` arrays, similar to the brute force approach. Time complexity: O(n) due to the three iterations (two for precomputation, one for calculating trapped water). Space complexity: O(n) due to the extra `left_max` and `right_max` arrays.",
            "Approach 3: Two Pointers. Initialize two pointers, `left` and `right`, at the beginning and end of the array, respectively. Also, initialize `left_max` and `right_max` to 0. While `left < right`, move the pointer that points to the smaller height. If `height[left] < height[right]`, check if `height[left]` is greater than `left_max`. If it is, update `left_max`. Otherwise, add `left_max - height[left]` to the total trapped water. Increment `left`. Do the same for the right pointer. Time complexity: O(n) because we iterate through the array once. Space complexity: O(1) because we only use a constant amount of extra space for the pointers and maximum heights."
        ],
        "ques_num": 42
    },
    {
        "question": "Multiply Strings",
        "description": "Given two non-negative integers that are represented as strings, return their product, also represented as a string, without using built-in integer conversion or libraries. Implement string multiplication as if performed by hand, digit by digit.",
        "approaches": [
            "Approach 1: Elementary multiplication. Iterate through each digit of the second number, and for each digit, multiply it with all digits of the first number. Store each of these intermediate products as strings. Then, add these intermediate product strings to get the final answer, similar to how it is done on paper. Time complexity is O(m^2 * n + m * n^2), where m and n are the lengths of the input strings. The space complexity is O(m*n) to store intermediate results.",
            "Approach 2: Elementary math using less intermediate space. Similar to Approach 1, but instead of storing each intermediate product as a separate string, directly add the result of multiplying each digit of num2 with num1 to the final result string. This requires careful management of carry-over values. Initialize an array of size m+n with zeros, and perform multiplication and addition in place in this array. The time complexity remains O(m*n), but the space complexity improves to O(m+n).",
            "Approach 3: Sum the products from all pairs of digits. Instead of multiplying each digit of one number by the entire other number, directly compute the product of each pair of digits (one from each number) and add the results in the correct place value in the final result string. This involves multiplying each digit of the first number by each digit of the second number and placing the result at the appropriate index (i+j+1, where i and j are the indices of the digits). The final string is initialized with zeros. This approach also eliminates the need to generate intermediate strings. The time complexity is O(m*n) and the space complexity is O(m+n)."
        ],
        "ques_num": 43
    },
    {
        "question": "Wildcard Matching",
        "description": "Given an input string `s` and a pattern `p`, implement wildcard pattern matching with support for '?' and '*' where '?' matches any single character and '*' matches any sequence of characters (including the empty sequence). Determine if the pattern matches the string.",
        "approaches": [
            "Approach 1: Recursion without Memoization. This is a naive approach where we recursively check all possible matches. The time complexity is O(2^(m+n)) in the worst case due to the exponential nature of recursion and the space complexity is O(m+n) due to the recursion depth, where m and n are the lengths of the string and pattern, respectively. This approach will likely result in TLE (Time Limit Exceeded) for larger inputs because it explores all possibilities without any optimization.",
            "Approach 2: Recursion with Memoization. This approach improves upon the naive recursive solution by storing the results of previously computed subproblems in a memoization table (e.g., a hash map). The time complexity is reduced to O(m*n) because each subproblem is solved only once. The space complexity is O(m*n) to store the memoization table, plus O(m+n) for the recursion stack. We first clean up the input by replacing more than one star in a row by a single star. Then we initialize the memoization hashmap. Then we recursively check all possible matches. This approach avoids redundant computations and provides a significant performance improvement over the naive recursive approach.",
            "Approach 3: Dynamic Programming. This approach uses a 2D table to store the matching results for substrings of `s` and `p`. The table `dp[i][j]` stores whether `s[0...i-1]` matches `p[0...j-1]`. The algorithm iterates through the table, filling it based on the characters in `s` and `p`. If `p[j-1]` is a regular character or '?', `dp[i][j]` is true if `dp[i-1][j-1]` is true and `s[i-1]` matches `p[j-1]`. If `p[j-1]` is '*', it can match zero or more characters, so `dp[i][j]` is true if either `dp[i-1][j]` (matching one or more characters) or `dp[i][j-1]` (matching zero characters) is true. The time complexity is O(m*n) because each cell in the table is visited once. The space complexity is O(m*n) to store the table. This approach is generally preferred over recursion with memoization because it avoids the overhead of recursive function calls and can be implemented iteratively."
        ],
        "ques_num": 44
    },
    {
        "question": "Jump Game II",
        "description": "Given an array of non-negative integers `nums`, where each element represents the maximum jump length from that position, find the minimum number of jumps required to reach the last index. Assume that you can always reach the last index.",
        "approaches": [
            "Approach 1: Brute-Force Backtracking. Explore all possible jump combinations from the start to reach the end. For each position, try all possible jump lengths (up to the value at that index) and recursively explore the subsequent positions. The minimum number of jumps among all successful paths is the answer. This approach has exponential time complexity, O(n^n) in the worst case, and O(n) space complexity due to the recursive call stack. It will likely result in Time Limit Exceeded for larger input arrays.",
            "Approach 2: Dynamic Programming (Top-Down with Memoization). Use recursion with memoization to avoid redundant calculations. Create a memoization table to store the minimum number of jumps required to reach the end from each index. For each index, if the value is already in the table, return it directly. Otherwise, recursively calculate the minimum jumps from each reachable position and store the result in the table. This reduces the time complexity compared to the backtracking approach. However, the time complexity is still O(n^2) in the worst case, and the space complexity is O(n) for the memoization table and recursion stack. This approach is still not optimal and might also lead to Time Limit Exceeded.",
            "Approach 3: Greedy Approach. Iterate through the array, keeping track of the current jump's end (`curEnd`) and the farthest reachable index (`curFar`). For each index `i`, update `curFar` to the maximum of `curFar` and `i + nums[i]`. If `i` reaches `curEnd`, it means we have finished the current jump, so increment the jump count and update `curEnd` to `curFar`. This ensures that we always make the jump that reaches the farthest, minimizing the number of jumps. The algorithm stops when `i` reaches the second to last index. This approach has a time complexity of O(n) because we iterate through the array once, and a space complexity of O(1) because we only use a few constant-size variables. This is the most optimal solution due to its linear time complexity and constant space complexity."
        ],
        "ques_num": 45
    },
    {
        "question": "Permutations",
        "description": "Given an array of distinct integers, find all possible permutations of the array elements.",
        "approaches": [
            "Approach 1: Brute-force using nested loops. Generate all possible arrangements of the elements by iterating through all possible combinations of indices using nested loops. This approach is highly inefficient, especially for larger input sizes. The time complexity is O(n!) because it generates all permutations, and the space complexity is O(1) (excluding the space to store the result). This is impractical due to the factorial time complexity.",
            "Approach 2: Iterative approach using insertion. Start with a single element list. Iteratively insert the next element into all possible positions within the existing lists of permutations. For example, to insert '3' into '[1,2]' we would create '[3,1,2]', '[1,3,2]' and '[1,2,3]'. This approach avoids explicit recursion but can still be inefficient. The time complexity is O(n!) and the space complexity is O(n!) because the number of generated permutations increases factorially with the number of elements.",
            "Approach 3: Backtracking with swapping. This is the standard and optimal approach. Implement a recursive function that explores all possible permutations by swapping elements. For each position in the array, swap it with all subsequent elements, recursively generate permutations for the remaining array, and then backtrack by swapping the elements back to their original positions. This ensures that all permutations are generated exactly once. The time complexity is O(n!) because it generates all possible permutations, and the space complexity is O(n) due to the recursion depth or O(n!) if we consider the space to store the result."
        ],
        "ques_num": 46
    },
    {
        "question": "Permutations II",
        "description": "Given an array of integers that may contain duplicate numbers, find all unique permutations of the array. The solution must not contain duplicate permutations.",
        "approaches": [
            "Approach 1: Naive Backtracking. Generate all possible permutations without considering duplicates. After generating all permutations, use a set to store the permutations to remove duplicates. This approach has a time complexity of O(N! * N) for generating permutations and O(N! * N) for removing duplicates using a set, where N is the length of the input array. The space complexity is O(N! * N) to store all permutations before removing duplicates and O(N) for the recursion stack.",
            "Approach 2: Backtracking with Swapping and Skipping Duplicates. Implement backtracking, but at each step, before swapping, check if the current number has already been used at the current position in the recursion. If it has, skip it. This avoids generating redundant permutations early on. The time complexity is still O(N!), but the constant factor is reduced due to skipping redundant branches. The space complexity is O(N) for the recursion stack and O(N) for storing the current permutation.",
            "Approach 3: Backtracking with Hash Table (Counter). Use a hash table (or counter) to store the frequency of each number in the input array. During backtracking, for each available number, check its count in the hash table. If the count is greater than 0, use the number in the current permutation and decrement its count in the hash table. After the recursive call, increment the count back. This avoids generating duplicate permutations by ensuring that each number is used no more times than it appears in the input array. The time complexity is O(\u2211 P(N, k)), where P(N,k) = N(N-1)...(N-k+1). The space complexity is O(N) for the hash table and O(N) for the recursion stack."
        ],
        "ques_num": 47
    },
    {
        "question": "Rotate Image",
        "description": "Given an n x n 2D matrix representing an image, rotate the image by 90 degrees (clockwise) in-place.",
        "approaches": [
            "Approach 1: Brute-Force using an auxiliary matrix. Create a new n x n matrix. Copy elements from the original matrix to the new matrix in the rotated order. Finally, copy the elements from the new matrix back to the original matrix. This approach requires extra space. The time complexity is O(n^2) because each element is visited and copied twice. The space complexity is O(n^2) due to the auxiliary matrix.",
            "Approach 2: Rotate in groups of four cells. Iterate through the matrix, focusing on groups of four cells that form a cycle when rotated. For each group, use a temporary variable to swap the values in the correct order, effectively rotating the group by 90 degrees. This approach does the rotation in-place, improving space complexity. The time complexity is O(n^2), as each cell is read and written once. The space complexity is O(1) because it uses only a constant amount of extra space.",
            "Approach 3: Transpose and Reflect. First, transpose the matrix along its main diagonal (swap matrix[i][j] with matrix[j][i] for i != j). Second, reflect the matrix horizontally by swapping elements in each row (swap matrix[i][j] with matrix[i][n-1-j]). Both operations can be performed in-place. This approach is considered optimal due to its simplicity and in-place nature, and it utilizes standard matrix operations. The time complexity is O(n^2) since we iterate through all matrix elements. The space complexity is O(1) as it operates in-place with no auxiliary data structures."
        ],
        "ques_num": 48
    },
    {
        "question": "Group Anagrams",
        "description": "Given an array of strings, group the anagrams together. Anagrams are words that contain the same letters but in a different order.",
        "approaches": [
            "Approach 1: Brute Force. For each string, compare it with every other string in the input array to check if they are anagrams. Anagram check involves sorting both strings and comparing them. Time complexity is O(N^2 * K log K), where N is the number of strings and K is the maximum length of a string. Space complexity is O(N), as we store the anagram groups.",
            "Approach 2: Categorize by Sorted String. Create a hash map where the key is the sorted string and the value is a list of anagrams. Iterate through the input array, sort each string, and use the sorted string as the key to store the original string in the hash map. Time complexity is O(N * K log K) because we sort each string of length K and we have N strings. Space complexity is O(NK) because we are storing all the strings in the hashmap.",
            "Approach 3: Categorize by Character Count. Create a hash map where the key is a count of each character in the string. Iterate through the input array, count the occurrences of each character in each string (26 characters in alphabet), and use the counts as the key to store the original string in the hash map. Time complexity is O(NK), where N is the number of strings and K is the maximum length of any string. Space complexity is O(NK), as we store the anagram groups. This is better than sorting since we are using a character count which is O(K) for each string instead of O(K log K)."
        ],
        "ques_num": 49
    },
    {
        "question": "Pow(x, n)",
        "description": "Implement a function to calculate x raised to the power of n (x^n) for given double x and integer n.",
        "approaches": [
            "Approach 1: Brute-force (Linear Exponentiation). This approach involves iteratively multiplying 'x' by itself 'n' times. If 'n' is negative, calculate 1 / x^(-n). This has a time complexity of O(n) because it performs 'n' multiplications. The space complexity is O(1) as it only uses a constant amount of extra space. This is the least efficient approach because the number of operations grows linearly with the exponent.",
            "Approach 2: Binary Exponentiation (Recursive). This approach uses recursion and the property x^n = (x^2)^(n/2) if n is even, and x * (x^2)^((n-1)/2) if n is odd. It also handles the case when n is negative by calculating 1 / x^(-n). The time complexity is O(log n) because the exponent is halved in each recursive call. The space complexity is O(log n) due to the recursive call stack. This approach is better than the brute-force approach, but recursive calls can add overhead.",
            "Approach 3: Binary Exponentiation (Iterative). This approach implements binary exponentiation iteratively using a while loop. If 'n' is odd, multiply the result by 'x' and decrement 'n'. Then square 'x' and divide 'n' by 2. The algorithm also handles the case where n is negative by inverting x. The time complexity is O(log n) because 'n' is halved in each iteration. The space complexity is O(1) as it uses a constant amount of extra space. This is the most optimal approach, because it achieves logarithmic time complexity without the overhead of recursive calls and minimal space usage."
        ],
        "ques_num": 50
    },
    {
        "question": "N-Queens",
        "description": "Given an `n x n` chessboard, find all possible arrangements of `n` queens such that no two queens attack each other. A queen can attack horizontally, vertically, and diagonally.",
        "approaches": [
            "Approach 1: Brute Force. Generate all possible board states with N queens and check if any two queens attack each other.  There are N^2 possibilities for the first queen, N^2 - 1 for the second, and so on. This leads to a time complexity of O(N^(2N)). The space complexity would be O(N^2) to represent the board. This approach is extremely inefficient and impractical for even small values of N.",
            "Approach 2: Backtracking without sets. Use backtracking to place queens one by one in each row. For each placement, check if the new queen is attacked by any previously placed queens by iterating through all previous queens to check for row, column, and diagonal conflicts. If no conflict exists, recursively call the backtracking function for the next row. If all queens are placed successfully, add the board to the solution. Time complexity is approximately O(N!), where N is the number of queens. Space complexity is O(N^2) to store the board and O(N) for the recursion call stack.",
            "Approach 3: Backtracking with sets for column, diagonal, and anti-diagonal tracking. Use backtracking to place queens one by one in each row. To optimize conflict detection, maintain three sets to track occupied columns, diagonals (row - col), and anti-diagonals (row + col). Before placing a queen, check if the column, diagonal, and anti-diagonal are already occupied. This avoids iterating through all previously placed queens for conflict checking. The time complexity is O(N!) because each queen has to be placed in each row and the number of valid board configurations is a function of N. The space complexity is O(N^2) to store the board and O(N) for the recursion call stack, plus O(N) to store the sets, as each set stores at most N items. This approach is superior because of the efficient conflict checking using sets, which reduces the time spent validating queen placements."
        ],
        "ques_num": 51
    },
    {
        "question": "N-Queens II",
        "description": "Given an `n x n` chessboard, the task is to find the number of ways to place `n` queens on the board such that no two queens attack each other. A queen can attack horizontally, vertically, and diagonally.",
        "approaches": [
            "Approach 1: Brute Force. Generate all possible board states with N queens. There are N^2 possible squares to place the first queen, N^2 - 1 to place the second, and so on. For each arrangement, check if the queens attack each other. If they don't, increment the solution count. This approach has a time complexity of O(N^(N^2)) because it explores every possible configuration. The space complexity is O(N^2) to store the board state. This is the worst approach because it explores many invalid states.",
            "Approach 2: Backtracking with Column Checking. Use backtracking to place queens one by one in each row. Before placing a queen, check if there is another queen in the same column. If there is, skip that cell. The time complexity is still exponential, but significantly better than brute force, roughly O(N^N) in the worst case, as we avoid placing queens in the same column. The space complexity is O(N) to store the column states. This approach is better than brute force as it prunes the search space by avoiding column conflicts.",
            "Approach 3: Backtracking with Column, Diagonal, and Anti-Diagonal Checking. Implement backtracking to place queens one by one in each row. Use sets to keep track of columns, diagonals, and anti-diagonals already occupied by queens. Before placing a queen, check if the column, diagonal, or anti-diagonal is already occupied. If so, skip that cell. The approximate time complexity is O(N!), as for the first queen, we have N options, for the next queen approximately N-2 options, and so on. The space complexity is O(N) to store the column, diagonal, and anti-diagonal states, as well as the recursion call stack. This approach is the most optimal because it efficiently prunes the search space, avoiding placing queens in any attacking position."
        ],
        "ques_num": 52
    },
    {
        "question": "Maximum Subarray",
        "description": "Given an integer array, find the contiguous subarray (containing at least one number) which has the largest sum and return its sum.",
        "approaches": [
            "Approach 1: Optimized Brute Force. This approach calculates the sum of all possible subarrays by iterating through the array with nested loops. The outer loop selects the starting point, and the inner loop extends the subarray to the end of the array, calculating the sum at each step and updating the maximum sum found so far. This avoids generating all subarrays, but still involves nested loops. Time complexity: O(N^2) where N is the length of the input array. Space complexity: O(1) because only a constant amount of extra space is used to store the current subarray sum and the maximum sum.",
            "Approach 2: Dynamic Programming (Kadane's Algorithm). Kadane's algorithm iterates through the array, keeping track of the current maximum subarray sum ending at each position and the overall maximum subarray sum. If the current subarray sum becomes negative, it is reset to 0, effectively starting a new subarray from the next element. This avoids unnecessary computations. Time complexity: O(N), where N is the length of the input array, because it iterates through the array once. Space complexity: O(1), because it uses a constant amount of extra space to store the current maximum and the overall maximum subarray sums.",
            "Approach 3: Divide and Conquer. The divide and conquer approach recursively divides the array into two halves, finds the maximum subarray sum in each half, and then finds the maximum subarray sum that crosses the middle point. The maximum subarray sum crossing the middle can be found in linear time by iterating from the middle to the left and to the right. The overall maximum is then the maximum of these three values. Time complexity: O(N log N), where N is the length of the array. The array is split log N times, and each split requires O(N) to find the maximum subarray crossing the midpoint. Space complexity: O(log N) due to the recursion stack."
        ],
        "ques_num": 53
    },
    {
        "question": "Spiral Matrix",
        "description": "Given a matrix, return all elements of the matrix in spiral order, starting from the top left corner and moving right, then down, then left, and then up.",
        "approaches": [
            "Approach 1: Naive Boundary Tracking. Initialize top, right, bottom, and left boundaries. Traverse the matrix in spiral order, adding elements to the result. Update boundaries after traversing each side. Before traversing from right to left or down to up, check if the row or column has already been traversed. The time complexity is O(M*N) because each element is visited once, where M is the number of rows and N is the number of columns. The space complexity is O(1) because no additional data structures are used, excluding the output array.",
            "Approach 2: Marking Visited Elements. Traverse the matrix in a spiral pattern. If a cell has been visited or a boundary is reached, change direction. Use a 'visited' marker to identify visited cells. If the matrix can be modified, use a value outside the matrix's element range as the marker. If modification is not allowed, create an auxiliary boolean matrix to track visited cells. The time complexity is O(M*N) because each element is visited once. The space complexity is O(1) if the input matrix can be modified, or O(M*N) if an auxiliary matrix is needed.",
            "Approach 3: Optimized Boundary Tracking with Direction Vector. Initialize a direction vector to represent the four directions (right, down, left, up). Use boundary variables (top, bottom, left, right) to keep track of the current boundaries. Iterate through the matrix in a spiral manner, using the direction vector to determine the next cell. When a boundary is reached, update the boundary variables and change the direction. The time complexity is O(M*N) since each element is visited once. The space complexity is O(1) because no extra space is used besides a few constant variables."
        ],
        "ques_num": 54
    },
    {
        "question": "Jump Game",
        "description": "Given an array of non-negative integers, where each element represents the maximum jump length from that position, determine if you are able to reach the last index starting from the first index.",
        "approaches": [
            "Approach 1: Backtracking. This is the most naive approach. The algorithm recursively explores all possible jump combinations. From each index, it tries all possible jumps (from 1 to the value at that index) and checks if any of these jumps lead to the last index. The time complexity is O(2^n) because, in the worst case, it explores all possible paths. The space complexity is O(n) due to the recursion depth, which can be at most n. Constraints: This approach is inefficient and will time out for larger input arrays.",
            "Approach 2: Dynamic Programming (Top-Down with Memoization). This approach optimizes the backtracking solution by storing the results of subproblems in a memoization table to avoid redundant computations. The algorithm recursively explores possible jumps, but before making a recursive call, it checks if the result for the current index is already stored in the memoization table. If it is, it returns the stored result. Otherwise, it computes the result, stores it in the table, and then returns it. The time complexity is O(n^2) because, in the worst case, it iterates through all possible jumps for each index. The space complexity is O(n) for the memoization table and the recursion stack. Constraints: Suitable for moderately sized arrays, but can still be less efficient than the bottom-up approach due to recursion overhead.",
            "Approach 3: Dynamic Programming (Bottom-Up). This approach eliminates recursion by building the solution iteratively from the end of the array to the beginning. An array `memo` is created where `memo[i]` indicates whether index `i` is reachable. The last index is initially marked as reachable. The algorithm iterates from the second-to-last index to the first index, checking for each index `i` if there exists a reachable index `j` such that `i + nums[i] >= j`. If such a `j` is found, then `memo[i]` is set to true. The time complexity is O(n^2) because, in the worst case, it iterates through all possible jumps for each index. The space complexity is O(n) for the `memo` array. Constraints: More efficient than top-down DP because of the absence of recursion overhead.",
            "Approach 4: Greedy. This approach iterates from right to left. It keeps track of the leftmost good index (lastGoodPos). For each index, it checks if nums[i] + i >= lastGoodPos. If it is, the index i becomes the new leftmost good index. In the end, if the leftmost good index is 0, it means that the first index is a good index. The time complexity is O(n), as it iterates through the array once. The space complexity is O(1), as it only uses a constant amount of extra space. Constraints: This is the most efficient approach and is suitable for large input arrays."
        ],
        "ques_num": 55
    },
    {
        "question": "Merge Intervals",
        "description": "Given a list of intervals, merge all overlapping intervals into non-overlapping intervals.",
        "approaches": [
            "Approach 1: Connected Components. Represent intervals as nodes in a graph. Add an edge between two nodes if their corresponding intervals overlap. Find connected components in the graph. Merge all intervals within each connected component into a single interval by taking the minimum start and maximum end of the intervals in the component. The time complexity is O(n^2) due to comparing each interval with every other interval to build the graph. The space complexity is O(n^2) in the worst case where all intervals overlap, resulting in a complete graph.",
            "Approach 2: Sorting. Sort the intervals by their start values. Iterate through the sorted intervals, merging overlapping intervals as encountered. If the current interval overlaps with the last merged interval, update the end of the last merged interval to be the maximum of the two ends. Otherwise, add the current interval to the merged list. The time complexity is dominated by the sorting step, O(n log n). The space complexity can be O(log n) if the sorting is done in place, or O(n) if a copy of the intervals is needed for sorting.",
            "Approach 3: Optimized Sorting (In-place merging). This approach builds upon the sorting approach by performing the merging operation in-place, avoiding the need for extra space beyond what the sorting algorithm might use. Sort intervals by start time. Iterate through sorted array and merge overlapping intervals. Because intervals are sorted, overlapping intervals will be adjacent. The time complexity remains O(n log n) due to sorting. The space complexity is O(1) if an in-place sorting algorithm like heap sort is used. If quicksort is used, then space complexity will be O(log n) due to the recursion stack."
        ],
        "ques_num": 56
    },
    {
        "question": "Insert Interval",
        "description": "Given a list of N non-overlapping intervals in ascending order of their start values, and a new interval, insert the new interval into the list while maintaining the ascending order and merging any overlapping intervals.",
        "approaches": [
            "Approach 1: Linear Search Insertion and Iterative Merging. First, iterate through the list of intervals to find the correct position to insert the new interval using linear search. Once the position is found, insert the new interval. Then, iterate through the updated list of intervals, and for each interval, check for overlaps with subsequent intervals. If overlaps are found, merge them and adjust the loop counter accordingly. Time complexity: O(N) for both insertion and merging, resulting in O(N) overall. Space complexity: O(1) as the merging is done in place.",
            "Approach 2: Binary Search Insertion and Iterative Merging. Use binary search to find the correct position to insert the new interval into the list, taking advantage of the sorted order. After inserting the interval, iterate through the list and merge overlapping intervals as in Approach 1. Time complexity: O(log N) for binary search insertion, and O(N) for merging. Therefore, the overall time complexity is O(N). Space complexity: O(1) since the merging is done in place.",
            "Approach 3: Create a new list and merge while iterating. Iterate through the original list of intervals. If the current interval in the list comes before the new interval, add it to the new list. If the current interval overlaps with the new interval, merge them. If the current interval comes after the new interval, add the new interval to the new list and proceed to add the current interval. After the iteration, return the new list. Time complexity: O(N) since we iterate through the entire list once. Space complexity: O(N) since a new list of intervals is created."
        ],
        "ques_num": 57
    },
    {
        "question": "Length of Last Word",
        "description": "Given a string 's' consisting of words and spaces, find the length of the last word in the string. A word is defined as a maximal substring consisting of non-space characters only.",
        "approaches": [
            "Approach 1: String Index Manipulation using Two Loops. Iterate from the end of the string to trim trailing spaces. Then, iterate again from the new end to find the length of the last word. The time complexity is O(N) because, in the worst case, we iterate through the entire string twice. The space complexity is O(1) as we use constant extra space.",
            "Approach 2: String Index Manipulation using One Loop. Iterate from the end of the string, keeping track of whether we are in a space or a word. If we encounter a non-space character after trailing spaces, start counting the length. If we encounter a space after a word, return the length. The time complexity is O(N) because, in the worst case, we iterate through the entire string once. The space complexity is O(1) as we use constant extra space.",
            "Approach 3: Using Built-in String Functions. First, trim the leading and trailing spaces using `trim()`. Then, find the index of the last space using `lastIndexOf(' ')`. Finally, calculate the length of the last word by subtracting the index of the last space from the total length of the trimmed string. The time complexity is O(N) because `trim()` and `lastIndexOf()` may iterate through the entire string. The space complexity is O(N) in Java because `trim()` creates a copy of the string."
        ],
        "ques_num": 58
    },
    {
        "question": "Spiral Matrix II",
        "description": "Given an integer `n`, generate an `n x n` matrix filled with elements from 1 to n^2 in spiral order.",
        "approaches": [
            "Approach 1: Brute-force traversal with boundary checks. Initialize an `n x n` matrix with zeros. Simulate the spiral traversal by moving right, down, left, and up. Keep track of visited cells using a separate boolean matrix or by marking cells in the original matrix with a special value (e.g., -1) after visiting them. This approach requires explicit boundary checks and direction changes. The time complexity is O(n^2) because we visit each cell once. The space complexity is O(n^2) due to the auxiliary matrix to track visited cells or O(1) if marking the original matrix, but modifying the input.",
            "Approach 2: Layer-by-layer traversal. Divide the matrix into concentric layers. For each layer, traverse the top row, right column, bottom row, and left column. Keep track of the boundaries of the current layer. This avoids the need for a separate visited matrix. The algorithm involves nested loops, where the outer loop iterates through the layers and the inner loops traverse each side of the layer. The time complexity is O(n^2) because each cell is still visited exactly once. The space complexity is O(1) as it uses constant extra space.",
            "Approach 3: Optimized spiral traversal with direction array. Use a direction array `dir` to store the changes in x and y coordinates for each direction (right, down, left, up). Maintain current row and column indices. When the next cell in the current direction is already filled or out of bounds, change the direction using `(d + 1) % 4`. This approach combines the layer-by-layer traversal with a direction array to simplify boundary checks and direction changes. The time complexity remains O(n^2) as each cell is visited once. The space complexity is O(1) because it only uses a constant amount of extra space."
        ],
        "ques_num": 59
    },
    {
        "question": "Permutation Sequence",
        "description": "Given an integer 'k' and an integer 'n', construct the k-th lexicographical permutation of the numbers 1 to n (numbering permutations from 0 to n!-1).",
        "approaches": [
            "Approach 1: Generate all permutations using backtracking, store them in a list, and return the k-th element. The time complexity is O(N! * N) to generate all permutations and O(1) to access the k-th element. The space complexity is O(N! * N) to store all permutations. This is inefficient for large values of 'n' due to the factorial time and space complexity, making it unsuitable for polynomial time constraints.",
            "Approach 2: Iteratively generate the next permutation using the D.E. Knuth algorithm, starting from the initial permutation [1, 2, ..., n], until the k-th permutation is reached. The time complexity is O(k * N), as each next permutation generation takes O(N) time, and we need to generate 'k' permutations. The space complexity is O(N) to store the current permutation. This is better than generating all permutations, but still has a dependency on k, and is not ideal for large values of k.",
            "Approach 3: Use the factorial number system to directly compute the k-th permutation. First, calculate the factorial representation of k. Then, iteratively construct the permutation by picking elements from the initial number array [1, 2, ..., n] based on the coefficients in the factorial representation. This avoids generating all or multiple permutations. The time complexity is O(N^2) because to delete elements from the list in a loop one has to perform N + (N-1) +...+ 1 = N(N-1)/2 operations. Space complexity is O(N) to store the factorial coefficients, the initial number array, and the resulting permutation."
        ],
        "ques_num": 60
    },
    {
        "question": "Rotate List",
        "description": "Given the head of a singly linked list, rotate the list to the right by k places.",
        "approaches": [
            "Approach 1: Convert the linked list to an array. Rotate the array using array rotation techniques. Then, create a new linked list from the rotated array. This is a brute-force approach involving extra space. Time Complexity: O(N) for converting to array, O(N) for rotating the array, and O(N) for creating the new linked list, resulting in O(N). Space Complexity: O(N) to store the linked list elements in an array.",
            "Approach 2: Iterate through the linked list and find the length 'n'. Then, traverse the list again to find the (n-k%n-1)-th node, which will be the new tail. The (n-k%n)-th node will be the new head. Connect the last node to the original head and set the next of the new tail to null. Time complexity: O(N) for finding the length of the list and O(N) for finding the new tail and head, resulting in O(N). Space Complexity: O(1). This approach improves upon Approach 1 by avoiding the extra space required for the array.",
            "Approach 3: (Optimal Approach) First, find the length 'n' of the linked list by traversing it. Make the linked list circular by connecting the tail to the head. Then, the new head will be the (n - k % n)-th node, and the new tail will be the node preceding the new head. To find these, traverse (n - k % n) nodes from the original head. Break the link between the new tail and the new head to finalize the rotation. Time Complexity: O(N) for finding the length and O(N) for traversing to the new head, resulting in O(N). Space Complexity: O(1). This is the most optimal approach because it achieves O(N) time complexity using constant space. This approach avoids unnecessary operations and directly manipulates the pointers to achieve the rotation in place."
        ],
        "ques_num": 61
    },
    {
        "question": "Unique Paths",
        "description": "Given a grid of size m x n, find the number of unique paths from the top-left cell to the bottom-right cell. You can only move right or down at any point in time.",
        "approaches": [
            "Approach 1: Recursive Solution. A straightforward approach is to use recursion. The number of paths to reach cell (m, n) is the sum of the number of paths to reach (m-1, n) and (m, n-1). The base case is when m = 1 or n = 1, in which case there is only one path. This approach has a time complexity of O(2^(m+n)) due to overlapping subproblems and a space complexity of O(m+n) due to the recursion depth. This solution is inefficient and will likely result in a timeout for larger grids.",
            "Approach 2: Dynamic Programming.  Create a 2D array `dp` of size m x n, where `dp[i][j]` stores the number of unique paths to reach cell (i, j). Initialize the first row and first column of `dp` to 1, as there is only one way to reach any cell in the first row or column. Then, iterate over the remaining cells and compute `dp[i][j] = dp[i-1][j] + dp[i][j-1]`. Finally, return `dp[m-1][n-1]`. This approach has a time complexity of O(m*n) and a space complexity of O(m*n). This is a significant improvement over the recursive approach.",
            "Approach 3: Combinatorial Solution.  The problem can be viewed as a combinatorial problem. To reach the bottom-right cell, we need to make a total of (m-1) down moves and (n-1) right moves. The total number of moves is (m-1) + (n-1) = m + n - 2. The number of unique paths is the number of ways to choose (m-1) down moves (or (n-1) right moves) from the total moves, which can be calculated using the binomial coefficient: C(m+n-2, m-1) or C(m+n-2, n-1). Using the formula, calculate the binomial coefficient using factorials: (m+n-2)! / ((m-1)! * (n-1)!). The best known algorithm to compute factorial function is done by Peter Borwein. The idea is to express the factorial as a product of prime powers, so that can be computed in O((M+N)(log(M+N) log log(M+N))^2) time. The space complexity is O(1). This approach is more efficient than dynamic programming, especially for large grids, due to its lower space complexity and optimized factorial calculation."
        ],
        "ques_num": 62
    },
    {
        "question": "Unique Paths II",
        "description": "Given a 2D grid where each cell represents whether it's an obstacle (1) or free space (0), determine the number of unique paths from the top-left cell (0,0) to the bottom-right cell (m-1, n-1). A robot can only move down or right at any point in time.",
        "approaches": [
            "Approach 1: Recursive Approach with Memoization. Implement a recursive function that explores all possible paths. At each cell, recursively call the function for the cell below and the cell to the right. Add the results if the cells are valid (not an obstacle and within bounds). Use memoization to store the results of already computed paths to avoid redundant calculations. Time complexity: O(M*N) due to memoization, where M and N are the dimensions of the grid. Space complexity: O(M*N) due to the memoization table and recursion stack.",
            "Approach 2: Dynamic Programming with Extra Space. Create a 2D DP table of the same size as the input grid. Initialize dp[0][0] to 1 if obstacleGrid[0][0] is not an obstacle, otherwise 0. Iterate through the grid, and for each cell (i, j), set dp[i][j] = dp[i-1][j] + dp[i][j-1] if obstacleGrid[i][j] is not an obstacle, else set dp[i][j] = 0. Handle edge cases for the first row and column. The final answer is stored in dp[m-1][n-1]. Time complexity: O(M*N). Space complexity: O(M*N) due to the extra DP table.",
            "Approach 3: Dynamic Programming In-Place. Use the input `obstacleGrid` itself as the DP table. Initialize `obstacleGrid[0][0]` to 1 if it's not an obstacle, otherwise 0. Iterate through the first row and first column, updating the values based on the obstacles and previous cells. Then, iterate through the rest of the grid, updating `obstacleGrid[i][j]` with the sum of the values from the top and left cells if it's not an obstacle, otherwise set it to 0. The final answer will be in `obstacleGrid[m-1][n-1]`. Time complexity: O(M*N). Space complexity: O(1) as we are using the input array as DP table."
        ],
        "ques_num": 63
    },
    {
        "question": "Minimum Path Sum",
        "description": "Given a 2D grid of numbers, find the minimum sum of numbers along a path from the top-left corner to the bottom-right corner. You can only move down or right at each step.",
        "approaches": [
            "Approach 1: Brute Force (Recursion). Explore all possible paths from the top-left to the bottom-right using recursion. For each cell, consider moving down or right and recursively calculate the minimum path sum from the next cell. The base case is when you reach the bottom-right cell, return its value. If you go out of bounds, return infinity. Time complexity: O(2^(m+n)), where m and n are the dimensions of the grid. This is because, at each step, we have two choices (down or right). Space complexity: O(m+n) due to the recursion depth.",
            "Approach 2: Dynamic Programming (2D). Create a 2D DP table of the same size as the input grid. dp[i][j] stores the minimum path sum from cell (i, j) to the bottom-right cell. Initialize the bottom-right cell of the DP table with the value of the corresponding cell in the grid. Iterate through the DP table in reverse order (from bottom-right to top-left). For each cell (i, j), calculate dp[i][j] as grid[i][j] + min(dp[i+1][j], dp[i][j+1]), handling boundary conditions appropriately. The minimum path sum from the top-left to the bottom-right will be stored in dp[0][0]. Time complexity: O(m*n), as we iterate through each cell in the grid once. Space complexity: O(m*n) for the DP table.",
            "Approach 3: Dynamic Programming (In-place). This approach is similar to the 2D DP approach, but instead of using an extra DP table, we modify the original grid in-place. Iterate through the grid in reverse order (from bottom-right to top-left). For each cell (i, j), update grid[i][j] to grid[i][j] + min(grid[i+1][j], grid[i][j+1]), handling boundary conditions appropriately. The minimum path sum from the top-left to the bottom-right will be stored in grid[0][0]. Time complexity: O(m*n), as we iterate through each cell in the grid once. Space complexity: O(1), as we modify the grid in-place, using no extra space. This is the most optimal solution because it achieves the same time complexity as the 2D DP approach but with significantly reduced space complexity."
        ],
        "ques_num": 64
    },
    {
        "question": "Valid Number",
        "description": "Given a string, determine if it is a valid number (integer or decimal). The number may contain digits, a sign (+ or -), an exponent (e or E), and a decimal point (.). The number must adhere to specific rules regarding the order and placement of these characters, such as only one exponent or decimal point, a digit must precede an exponent, and an integer must follow an exponent.",
        "approaches": [
            "Approach 1: Using regular expressions. Construct a regular expression pattern that matches the valid number format. While concise, creating and maintaining a correct regex for all edge cases can be complex and error-prone. Time complexity is O(N) in the worst case where N is the length of the string, as the regex engine might backtrack. Space complexity is O(1) if the regex engine uses constant extra space, but can be O(N) depending on the implementation if backtracking occurs.",
            "Approach 2: Iterating and checking character by character based on the rules.  Iterate through the string, maintaining flags to track whether a digit, sign, exponent, or decimal point has been seen. Check each character against the defined rules, and return false immediately if any rule is violated. This is more explicit and easier to understand than regex. The Time complexity is O(N) where N is the length of the string, as each character is visited once. The Space complexity is O(1) as only a fixed number of boolean variables are used.",
            "Approach 3: Deterministic Finite Automaton (DFA). Design a DFA with states representing the possible stages of parsing a valid number. Each state transition is determined by the current character in the input string. If the DFA reaches a valid final state after processing the entire string, the number is valid. This approach handles the complex state transitions and edge cases in a structured way, making the code more maintainable and easier to reason about. The Time complexity is O(N) where N is the length of the string, as each character is processed by the DFA. The Space complexity is O(1), as the DFA's state transitions are precomputed and stored in a fixed-size table."
        ],
        "ques_num": 65
    },
    {
        "question": "Plus One",
        "description": "Given a non-empty array of decimal digits representing a non-negative integer, increment one to the integer. The digits are stored such that the most significant digit is at the head of the list, and each element in the array contains a single digit. You may assume the integer does not contain any leading zero, except the number 0 itself.",
        "approaches": [
            "Approach 1: Convert the array to an integer, add one, and convert back to an array. This approach involves iterating through the array to form the integer, adding one, and then extracting digits to form a new array. However, it's highly susceptible to integer overflow issues, especially for large arrays. The time complexity is O(N) for conversion to integer and O(M) for conversion back to array where N is the number of digits and M is the number of digits after incrementing, and space complexity is O(M). This approach is not feasible for large inputs due to potential overflow, and is generally discouraged.",
            "Approach 2: Iterate from the least significant digit, incrementing by one and handling carry. This approach mimics manual addition. Start from the rightmost digit, add one, and if the result is 10, set the digit to 0 and carry over 1 to the next digit. Continue until there's no carry or the beginning of the array is reached. If a carry remains after processing all digits, allocate a new array of size N+1, set the first element to 1, and copy the remaining digits. The time complexity is O(N) in the worst case (all 9s), and the space complexity is O(1) in the average case (in-place modification) but O(N) in the worst case where a new array needs to be allocated.",
            "Approach 3: Optimized in-place addition with carry. Iterate through the array from the rightmost digit. If a digit is less than 9, increment it and return the modified array directly. If a digit is 9, set it to 0 and continue the loop. If the loop completes without returning, it means all digits were 9. Create a new array of size n+1, set the first element to 1, and return it. The time complexity is O(N) in the worst case (all 9s), but often completes in O(1) if the rightmost digit is not a 9. The space complexity is O(1) on average (in-place modification) and O(N) in the worst case when a new array is required. This approach is the best as it minimizes both time and space usage while directly addressing the addition and carry propagation."
        ],
        "ques_num": 66
    },
    {
        "question": "Add Binary",
        "description": "Given two binary strings, `a` and `b`, compute their sum (also a binary string) without using built-in addition or parsing the entire string into integers due to potential overflow.",
        "approaches": [
            "Approach 1: Convert to Integer, Sum, Convert back to Binary. This involves converting the binary strings `a` and `b` into integers, summing them, and converting the result back into a binary string.  In Java, this approach is limited by the length of the input strings `a` and `b`, as very long strings will result in integers that don't fit into Integer, Long, or BigInteger.  The time complexity is O(N+M) for converting the strings to integers and back, where N and M are the lengths of `a` and `b`. Space complexity is O(1), assuming the integer representation takes constant space.",
            "Approach 2: Bit-by-Bit Computation. This approach mimics manual binary addition. Starting from the least significant bit, it iterates through the strings, adding the bits and any carry from the previous position. The result for each bit is appended to a string. The carry is calculated and used in the next iteration.  The time complexity is O(max(N, M)), where N and M are the lengths of the input strings `a` and `b`. The space complexity is O(max(N, M)) to store the resulting binary string and the carry.",
            "Approach 3: Bit Manipulation. This approach uses bitwise operators (XOR and AND) to perform binary addition.  XOR gives the sum without carry, and AND gives the carry.  The algorithm iterates, calculating the sum without carry (a XOR b) and the carry (a AND b) left-shifted by one position.  The process repeats until the carry becomes zero. The time complexity is O(N+M) where N and M are the lengths of the input strings `a` and `b`. The space complexity is O(max(N, M)) to keep the answer. In the case of large input numbers, BigInteger is required."
        ],
        "ques_num": 67
    },
    {
        "question": "Text Justification",
        "description": "Given an array of words and a maximum width maxWidth, format the text such that each line has exactly maxWidth characters and is fully justified. Pack as many words as possible in each line. Extra spaces between words should be distributed as evenly as possible. If the number of spaces on a line do not divide evenly between words, the empty slots on the left will be assigned more spaces than the slots on the right. The last line of text should be left justified and no extra space is inserted between words.",
        "approaches": [
            "Approach 1: Brute-force approach. Iterate through all possible combinations of words to fit on each line. For each combination, check if the length is within the maxWidth constraint. If it is, calculate the spaces and construct the line. Choose the combination that maximizes the number of words on each line. Time complexity would be exponential, O(2^n), where n is the number of words, due to checking all combinations. Space complexity would be O(m), where m is the maximum width, to store the formatted line.",
            "Approach 2: Greedy approach with backtracking. Greedily add words to a line until the next word would exceed maxWidth. If it does, construct the line with the current set of words and move to the next line. Backtrack if a better combination is possible (e.g., leaving one word behind to better fill the next line). This approach is better than brute force but still has the potential for exponential time complexity in worst-case scenarios where extensive backtracking is needed, although it performs much better on average. The time complexity is hard to define but is significantly better than O(2^n), potentially closer to O(n^2). Space complexity remains O(m) for storing the formatted line.",
            "Approach 3: Optimal Greedy Approach. Iterate through the words linearly. For each line, greedily add words until adding the next word would exceed maxWidth. Once a line is full, calculate the number of spaces needed and distribute them evenly between the words. For the last line, left-justify with single spaces between words. This approach has a time complexity of O(n), where n is the number of words, as each word is processed once to determine line breaks and space distribution. The space complexity is O(m), where m is the maxWidth, to store the formatted line. This approach is optimal because it directly addresses the problem constraints with linear time complexity, avoiding unnecessary backtracking or combinatorial exploration."
        ],
        "ques_num": 68
    },
    {
        "question": "Sqrt(x)",
        "description": "Given a non-negative integer 'x', compute its integer square root. The integer square root of x is the largest integer 'k' such that k*k <= x. The function should return this integer 'k'.",
        "approaches": [
            "Approach 1: Pocket Calculator Algorithm. This approach utilizes built-in exponential functions and natural logarithms to compute the square root. The formula used is sqrt(x) = e^(0.5 * ln(x)). This is essentially a 'cheat' because it relies on non-elementary function usage. Time complexity: O(1). Space complexity: O(1). However, this approach might have precision issues due to the limitations of floating-point arithmetic, and it does not truly reflect the algorithmic thinking expected in an interview setting.",
            "Approach 2: Binary Search. This approach searches for the square root within a defined range. The left boundary is initialized to 2 (or 1 for x < 2) and the right boundary is x / 2. In each iteration, the middle element (pivot) is calculated, and its square is compared to x. If the square is greater than x, the right boundary is moved to pivot - 1. If the square is less than x, the left boundary is moved to pivot + 1. If the square is equal to x, the pivot is the square root. The process repeats until left > right. Time complexity: O(log x). Space complexity: O(1). This is an improvement over the Pocket Calculator approach because it does not rely on library functions and provides a more fundamental algorithmic solution.",
            "Approach 3: Newton's Method. This approach uses an iterative method to approximate the square root. It starts with an initial guess, x0, and iteratively refines the guess using the formula x_(i+1) = 0.5 * (x_i + x / x_i). The iteration continues until the difference between successive guesses is smaller than a predefined error threshold. This method converges quadratically, meaning it typically requires fewer iterations than binary search to achieve the same level of accuracy. Time complexity: O(log log N) since the set converges quadratically. Space complexity: O(1). This is generally considered the most efficient approach because of its faster convergence rate compared to binary search."
        ],
        "ques_num": 69
    },
    {
        "question": "Climbing Stairs",
        "description": "You are climbing a staircase. It takes n steps to reach the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top?",
        "approaches": [
            "Approach 1: Brute Force. The algorithm explores all possible combinations of 1 and 2 steps recursively. The function calls itself for step i+1 and i+2, summing the returned values. The base cases are when i equals n (return 1) and when i is greater than n (return 0). The time complexity is O(2^n) due to the exponential nature of the recursion tree. The space complexity is O(n) due to the depth of the recursion tree.",
            "Approach 2: Recursion with Memoization. This approach improves upon the brute force method by storing the results of subproblems in a memo array. Before computing the number of ways for a given step, it checks if the result is already stored in the memo. If so, it returns the stored value; otherwise, it computes the result, stores it in the memo, and returns it. This avoids redundant calculations. The time complexity is O(n) because each step is computed only once. The space complexity is O(n) due to the memo array and the recursion stack.",
            "Approach 3: Fibonacci Number. This approach recognizes that the number of ways to climb the staircase is equivalent to the (n+1)-th Fibonacci number, where F(1) = 1 and F(2) = 2. It calculates the nth Fibonacci number using an iterative approach. The time complexity is O(n) because a single loop is required to calculate the nth Fibonacci number. The space complexity is O(1) because constant space is used.",
            "Approach 4: Binary Method. This approach uses matrix multiplication to obtain the nth Fibonacci Number. The time complexity is O(log n). Traversing on log n bits. The space complexity is O(1).",
            "Approach 5: Fibonacci Formula. This approach uses Binet's formula to directly compute the nth Fibonacci number. The time complexity is O(log n) due to the power method used in the formula. The space complexity is O(1) because constant space is used."
        ],
        "ques_num": 70
    },
    {
        "question": "Simplify Path",
        "description": "Given a string 'path', which is an absolute path (starting with a slash '/') to a file or directory in a Unix-style file system, convert it to the simplified canonical path.",
        "approaches": [
            "Approach 1: Brute-force string manipulation. Split the path string by '/', iterate through the resulting array, and build a new path string. Handle '.' by doing nothing, '..' by moving up a directory (removing the last directory in the path), and legitimate directory names by appending them to the new path. This approach is inefficient due to repeated string concatenation and manipulation. The time complexity is O(N^2) in the worst case due to string concatenation, where N is the length of the path. The space complexity is also O(N) to store the simplified path string.",
            "Approach 2: Using a Stack to store directory names. Split the path string by '/'. Iterate through the resulting array. If the component is '.' or empty, ignore it. If the component is '..', pop from the stack if the stack is not empty. If the component is a directory name, push it onto the stack. Finally, construct the simplified path by popping elements from the stack and joining them with '/'. The time complexity is O(N) for splitting, iterating, and constructing the final path. The space complexity is O(N) for the stack to store directory names in the worst case.",
            "Approach 3: In-place Stack using a string builder. Iterate through the input string character by character. Keep track of directory components. When a '/' is encountered, process the current directory component. For '.' and empty components, ignore. For '..', remove the last directory component from the string builder if it exists. For a legitimate directory name, append it to the string builder. This avoids the overhead of splitting the string and uses constant extra space, except for the string builder. The time complexity is O(N) and the space complexity is O(N) in the worst case for string builder, where N is the length of the input path."
        ],
        "ques_num": 71
    },
    {
        "question": "Set Matrix Zeroes",
        "description": "Given a matrix (2D array) of integers, if any cell within the matrix is zero, set its entire row and column to zero. This must be done in-place, meaning the space complexity should ideally be O(1).",
        "approaches": [
            "Approach 1: Brute-force approach using additional memory. Iterate through the matrix, and when a zero is found, record the row and column indices in two separate sets (one for rows and one for columns). After the first pass, iterate through the matrix again. If a cell's row or column is present in the respective sets, set the cell to zero. This approach has a time complexity of O(M * N) where M and N are the dimensions of the matrix, and a space complexity of O(M + N) due to the sets.",
            "Approach 2: Using the first row and column as flags. Iterate through the matrix. If a cell matrix[i][j] is zero, set matrix[i][0] and matrix[0][j] to zero. Use a separate variable to track if the first column needs to be zeroed out. After the first pass, iterate from matrix[1][1] onwards. If matrix[i][0] or matrix[0][j] is zero, set matrix[i][j] to zero. Finally, zero out the first row and first column based on the flags set. The time complexity is O(M * N) and the space complexity is O(1), improving upon the space complexity of the first approach.",
            "Approach 3: Optimized in-place modification with O(1) space. This approach is identical to approach 2. Iterate through the matrix. If a cell matrix[i][j] is zero, set matrix[i][0] and matrix[0][j] to zero. Use a separate variable to track if the first column needs to be zeroed out. After the first pass, iterate from matrix[1][1] onwards. If matrix[i][0] or matrix[0][j] is zero, set matrix[i][j] to zero. Finally, zero out the first row and first column based on the flags set. The time complexity is O(M * N) and the space complexity is O(1). This optimized in-place modification improves space complexity while maintaining the required result."
        ],
        "ques_num": 73
    },
    {
        "question": "Search a 2D Matrix",
        "description": "Given an m x n matrix where each row and column is sorted in ascending order, determine if a given target value exists within the matrix.",
        "approaches": [
            "Approach 1: Brute Force. Iterate through each element of the matrix and compare it with the target value. If the target is found, return true; otherwise, return false after checking all elements. This approach has a time complexity of O(m*n) because it requires visiting every element in the matrix. The space complexity is O(1) as it uses constant extra space.",
            "Approach 2: Row-wise Binary Search. Iterate through each row of the matrix and perform a binary search for the target value within that row. If the target is found in any row, return true; otherwise, return false after checking all rows. The time complexity is O(m*log(n)) because we perform a binary search (O(log(n))) on each row (m rows). The space complexity is O(1) as it uses constant extra space. This is better than Approach 1 because binary search is more efficient than linear search for sorted data.",
            "Approach 3: Binary Search on a Virtual Sorted Array. Treat the m x n matrix as a single sorted array of size m*n. Apply binary search on this virtual array, calculating the row and column indices from the middle index during each step. This approach has a time complexity of O(log(m*n)) because it performs binary search on the entire matrix. The space complexity is O(1) as it uses constant extra space. This is the most optimal approach because it leverages the sorted nature of both rows and columns to achieve logarithmic time complexity."
        ],
        "ques_num": 74
    },
    {
        "question": "Sort Colors",
        "description": "Given an array containing only 0s, 1s, and 2s, sort the array in-place so that the 0s come first, followed by the 1s, and then the 2s. This is also known as the Dutch National Flag problem.",
        "approaches": [
            "Approach 1: Brute Force - Counting Sort. Iterate through the array, count the occurrences of 0, 1, and 2. Then, overwrite the array with the appropriate number of 0s, 1s, and 2s based on the counts. This algorithm requires two passes: one for counting and one for overwriting. The time complexity is O(n), and the space complexity is O(1) because we only use a fixed number of variables to store the counts. However, it's less efficient because it's not an in-place sorting algorithm.",
            "Approach 2: Two-Pass Partitioning. First, partition the array into two parts: 0s on the left and the rest on the right. Then, partition the right part into 1s on the left and 2s on the right. This approach involves two passes through the array. The time complexity is O(n), and the space complexity is O(1) because it's done in-place. It improves upon the first approach by sorting in-place, but still requires two passes.",
            "Approach 3: Three-Way Partitioning (Dutch National Flag Algorithm). Use three pointers: `p0` (rightmost boundary of 0s), `curr` (index of current element), and `p2` (leftmost boundary of 2s). Iterate through the array while `curr <= p2`. If `nums[curr]` is 0, swap it with `nums[p0]` and increment both `curr` and `p0`. If `nums[curr]` is 2, swap it with `nums[p2]` and decrement `p2`. If `nums[curr]` is 1, increment `curr`. This sorts the array in a single pass. The time complexity is O(n), and the space complexity is O(1) because it sorts in-place using only constant extra space. This is the most optimal approach because it sorts the array in-place with a single pass."
        ],
        "ques_num": 75
    },
    {
        "question": "Minimum Window Substring",
        "description": "Given two strings `S` and `T`, find the minimum window in `S` which has all the characters of `T`. A window is considered 'desirable' if it contains all characters from `T`.",
        "approaches": [
            "Approach 1: Brute-force. Generate all possible substrings of `S` and check if each substring contains all characters of `T`. If a substring contains all characters of `T`, compare its length with the current minimum length and update the minimum window. The algorithm iterates through all possible start and end indices of substrings in S, leading to a time complexity of O(N^3) where N is the length of S. Checking if a substring contains all characters of T takes O(M) time, where M is the length of T. The space complexity is O(M) to store the character counts of T. This approach is inefficient and will likely result in a timeout for larger inputs.",
            "Approach 2: Basic Sliding Window. Use two pointers, `left` and `right`, to maintain a sliding window over `S`. Expand the window by moving the `right` pointer until the window contains all characters of `T`. Once the window is 'desirable', contract the window by moving the `left` pointer to find the minimum possible window. The algorithm involves iterating through the string S once by left pointer and once by right pointer. The time complexity is O(|S| + |T|), where |S| and |T| are the lengths of strings S and T, respectively. The space complexity is O(|S| + |T|), where |S| accounts for the maximum possible window size and |T| accounts for the character count map.",
            "Approach 3: Optimized Sliding Window. First, filter the string `S` to create a new list `filtered_S` containing only the characters from `S` that are present in `T`, along with their original indices in `S`. Then, apply the sliding window approach on `filtered_S`. This reduces the number of iterations in the sliding window, especially when the length of `T` is much smaller than the length of `S`, and `S` contains many characters not present in `T`. The time complexity is O(2 * |filtered_S| + |S| + |T|), which can be significantly better than the basic sliding window approach when |filtered_S| is much smaller than |S|. The space complexity remains O(|S| + |T|)."
        ],
        "ques_num": 76
    },
    {
        "question": "Combinations",
        "description": "Given two integers `n` and `k`, return all possible combinations of `k` numbers out of the range `[1, n]`.",
        "approaches": [
            "Approach 1: Brute-force using nested loops. Generate all possible combinations of length `k` by iterating through all possible selections using `k` nested loops. This is highly inefficient as the number of loops depends on `k`. Time complexity is O(n^k), and space complexity is O(1) excluding the output list. This approach is not feasible for larger values of `k` and `n` due to its exponential time complexity.",
            "Approach 2: Recursive Backtracking. Recursively explore all potential combinations. For each number from `1` to `n`, either include it in the current combination or exclude it. If the current combination has size `k`, add it to the result. Time complexity is O(k * C(n, k)), where C(n, k) is the binomial coefficient (n choose k), representing the number of combinations. The space complexity is O(k * C(n, k)) to store the combinations and O(n) due to recursive stack depth in the worst case.",
            "Approach 3: Lexicographic (Binary Sorted) Combination Generation. This approach generates combinations in lexicographical order. It uses an array `nums` of size `k+1`, initialized with `[1, 2, ..., k, n+1]`. The algorithm iterates while the first element is less than `k`. In each iteration, it adds the first `k` elements of `nums` to the result. Then, it finds the first element `nums[j]` such that `nums[j] + 1 != nums[j+1]` and increments `nums[j]`. This efficiently generates the next combination in lexicographic order. Time complexity is O(k * C(n, k)), and space complexity is O(C(n, k)) to keep all the combinations for an output. Although the time complexity is the same as Approach 2, this approach is faster because it avoids the overhead of recursive function calls, resulting in better performance, especially in languages like Python."
        ],
        "ques_num": 77
    },
    {
        "question": "Subsets",
        "description": "Given a set of distinct integers, nums, return all possible subsets (the power set). The solution set must not contain duplicate subsets. You may return the subsets in any order.",
        "approaches": [
            "Approach 1: Cascading. Start with an empty subset. For each number in the input, iterate through the existing subsets and create a new subset by adding the current number to each of them. Add the newly created subsets to the output. Time complexity: O(N * 2^N) to generate all subsets and then copy them into the output list. Space complexity: O(N * 2^N), where N is the number of elements in the input array.",
            "Approach 2: Backtracking. Use a recursive backtracking approach to explore all possible combinations of elements. Iterate over all possible lengths of subsets, from 0 to N (the length of the input array). In each recursive call, either include or exclude the current element. Time complexity: O(N * 2^N) to generate all subsets. Space complexity: O(N) for the recursion stack, which can be optimized to O(1) if modifications are done in-place.",
            "Approach 3: Lexicographic (Binary Sorted) Subsets. Generate all possible binary bitmasks of length N, where N is the number of elements in the input array. Each bit in the bitmask represents whether the corresponding element is present in the subset (1) or absent (0). Map each bitmask to its corresponding subset. Time complexity: O(N * 2^N) to generate all subsets. Space complexity: O(2^N) to keep all the subsets of length N, since each of N elements could be present or absent."
        ],
        "ques_num": 78
    },
    {
        "question": "Word Search",
        "description": "Given a 2D character board and a word, determine if the word can be found in the board. The word can be constructed from letters of sequentially adjacent cells, where adjacent cells are horizontally or vertically neighboring. The same letter cell may not be used more than once.",
        "approaches": [
            "Approach 1: Brute-Force Backtracking with No Optimizations. Iterate through each cell in the board and start a depth-first search (DFS) to find the word. In the DFS, explore all four possible directions (up, down, left, right) recursively. If the current character matches the corresponding character in the word, continue exploring. If the entire word is found, return true. If a path leads to a dead end or an invalid character, backtrack and try another path. Time complexity: O(N * 4^L), where N is the number of cells in the board and L is the length of the word. This is because for each cell, we might explore up to 4 directions for each character in the word. Space complexity: O(L) due to the recursive call stack.",
            "Approach 2: Backtracking with Visited Set. This is an improvement over the brute-force approach. Maintain a visited set to keep track of cells already visited in the current path. Before exploring a neighboring cell, check if it has already been visited. This prevents cycles and avoids infinite loops. The time complexity remains O(N * 3^L) in the worst case (since we won't go back to the cell we just came from), as each cell has at most 3 unexplored neighbors after the first step. The space complexity is O(L) for the call stack, plus O(L) in the worst case for the visited set, to store the path of length L. Thus, the overall space complexity is O(L).",
            "Approach 3: Backtracking with In-Place Modification (Optimal). Instead of using a separate visited set, temporarily modify the board in-place to mark visited cells during the DFS. For example, change the character of the visited cell to a special character (e.g., '#'). After exploring all possible paths from a cell, revert the modification to restore the original character. This approach avoids the overhead of maintaining a visited set and reduces the space complexity. The time complexity remains O(N * 3^L) in the worst case, as we still explore at most 3 neighbors. The space complexity is optimized to O(L) due to the recursive call stack, as we no longer need extra space for the visited set. This is the most optimal approach due to its efficient use of space."
        ],
        "ques_num": 79
    },
    {
        "question": "Remove Duplicates from Sorted Array II",
        "description": "Given a sorted array, remove the duplicates in-place such that each element appears at most twice. Return the new length of the array. You must do this in-place without using extra space.",
        "approaches": [
            "Approach 1: Popping Unwanted Duplicates. Iterate through the array with a pointer `i` and a counter `count` to track the occurrences of each element. If an element appears more than twice, remove it from the array using `pop()` or `remove()` operation. This requires updating the array indices after each removal. The time complexity is O(N^2) in the worst case (when all elements are the same), because the `pop()` operation takes O(N) time. The space complexity is O(1) since the array is modified in-place.",
            "Approach 2: Overwriting Unwanted Duplicates. Use two pointers, `i` and `j`, where `i` iterates through the array and `j` points to the next available position to overwrite. Maintain a counter `count` to track the occurrences of each element. If an element appears at most twice, copy it from index `i` to index `j` and increment `j`. Otherwise, skip the element at index `i`. The time complexity is O(N) since each element is processed at most once. The space complexity is O(1) since the array is modified in-place.",
            "Approach 3: Optimized Overwriting Duplicates. This approach is similar to approach 2 but avoids unnecessary copying. Iterate through the array with index `i`. If `i < 2` or `nums[i] != nums[i-2]`, then copy `nums[i]` to `nums[j]` and increment `j`. This works because we only need to check the element two positions back to determine if we have exceeded the allowed duplicate count. The time complexity is O(N) since each element is processed exactly once. The space complexity is O(1) since the array is modified in-place. This is the most efficient approach as it minimizes comparisons and assignments while fulfilling the in-place requirement."
        ],
        "ques_num": 80
    },
    {
        "question": "Search in Rotated Sorted Array II",
        "description": "Given a rotated sorted array that may contain duplicate elements, determine if a target element exists within the array. This problem is an extension of the \"Search in Rotated Sorted Array\" problem, but with the added constraint of potential duplicate values.",
        "approaches": [
            "Approach 1: Linear Search. Iterate through the entire array and check if each element is equal to the target. This is a brute-force approach. The time complexity is O(n) in the worst and average case, where n is the length of the array. The space complexity is O(1) as it uses constant extra space.",
            "Approach 2: Modified Binary Search with Linear Scan for Duplicates. Use a modified binary search to handle the rotated nature of the array. If `arr[mid] == arr[start]`, linearly scan from `start` until `arr[start] != arr[mid]` to shrink the search space, or until `start == mid`. If duplicates cause the algorithm to degrade to linear search, the time complexity becomes O(n) in the worst case (when many duplicates exist). In the best case (no duplicates or target found early), it is O(log n). The space complexity is O(1).",
            "Approach 3: Optimized Binary Search. Implement a binary search that carefully handles the cases where `arr[mid] == arr[start]`. Instead of a linear scan, increment `start` to shrink the search space when `arr[mid] == arr[start]`. This has a worst-case time complexity of O(n) when the array contains many duplicate elements and the target is not present, as the `start` pointer might have to increment many times. The best-case and average-case time complexity is O(log n) when the array has few duplicates or the target is found quickly. The space complexity is O(1) because it uses constant extra space."
        ],
        "ques_num": 81
    },
    {
        "question": "Remove Duplicates from Sorted List II",
        "description": "Given a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list. Return the linked list sorted.",
        "approaches": [
            "Approach 1: Using a hash map to count the frequency of each node's value. Iterate through the list, storing each value and its count in the hash map. Then, create a new linked list by iterating through the original list again and only adding nodes whose values have a frequency of 1 in the hash map. This approach requires extra space to store the hash map and to create a new linked list. Time complexity is O(N) for iterating through the list and constructing the hash map, and O(N) for iterating through the list again to create a new list. The space complexity is O(N) in the worst case, where N is the number of unique elements in the list.",
            "Approach 2: Iterating through the sorted linked list and identifying consecutive duplicate nodes. While traversing, keep track of the previous node. If a duplicate sequence is encountered, move the current pointer to the end of the duplicate sequence. Then, adjust the `next` pointer of the previous node to skip the entire sequence. If the duplicate sequence starts from the head, update the head pointer accordingly. This approach avoids creating extra copies of the list, but requires careful handling of edge cases (e.g., duplicate sequences at the head or tail). The time complexity is O(N), as we traverse the list once. The space complexity is O(1) because we only use a few constant extra variables.",
            "Approach 3: (Sentinel Node and Predecessor) This approach uses a sentinel node to handle the case where the head of the list needs to be removed. It iterates through the list, keeping track of the predecessor node. If a duplicate sublist is found (i.e., head.val == head.next.val), it moves the head pointer to the end of the duplicate sublist, and then updates the predecessor's next pointer to skip the duplicate sublist. If no duplicates are found, it moves the predecessor pointer forward. This method avoids creating additional data structures and handles edge cases effectively. Time complexity: O(N), as we make one pass through the list. Space complexity: O(1), as we use only constant extra space."
        ],
        "ques_num": 82
    },
    {
        "question": "Remove Duplicates from Sorted List",
        "description": "Given a sorted linked list, remove all duplicates such that each element appears only once.",
        "approaches": [
            "Approach 1: Using a HashSet. Iterate through the linked list, adding each node's value to a HashSet. If a value is already in the HashSet, remove the node from the linked list. This approach has a time complexity of O(n) because we iterate through the list once. The space complexity is also O(n) in the worst case, where n is the number of nodes in the list, as the HashSet could potentially store all unique values.",
            "Approach 2: Two Pointers with additional memory. Use one pointer to traverse the list and another to keep track of the unique element seen so far. Use a HashMap to store all the elements seen so far. If the current element is already in the HashMap, then delete it. This approach has O(n) time complexity because each element is visited once. The space complexity is O(n) due to the HashMap.",
            "Approach 3: Iterative in-place removal. Iterate through the linked list with a single pointer, `current`. While `current` and `current.next` are not null, check if `current.val` is equal to `current.next.val`. If they are equal, update `current.next` to `current.next.next` to skip the duplicate. If they are not equal, move `current` to `current.next`. Since the list is sorted, all duplicates will be adjacent. This approach has a time complexity of O(n), as we iterate through the list once. The space complexity is O(1) because we are modifying the list in place without using any additional data structures. This is the most optimal approach as it provides the best space complexity."
        ],
        "ques_num": 83
    },
    {
        "question": "Largest Rectangle in Histogram",
        "description": "Given an array of integers representing the heights of bars in a histogram, find the largest rectangular area possible in the histogram.",
        "approaches": [
            "Approach 1: Brute Force. Iterate through all possible pairs of bars (left and right boundaries). For each pair, find the minimum height bar between them. The area formed by this pair is the minimum height multiplied by the distance between the bars. Track the maximum area found. The time complexity is O(n^3) because we iterate through all possible pairs O(n^2) and for each pair, we have to find the minimum height bar O(n). The space complexity is O(1) because no extra space is used.",
            "Approach 2: Better Brute Force. Iterate through all possible pairs of bars (left and right boundaries). For each pair, instead of finding the minimum height bar by iterating through the bars between the pair every time, we can maintain the minimum height bar of the previous pair and compare it with the current bar. The time complexity is O(n^2) since every possible pair is considered. Space complexity is O(1) as no extra space is used.",
            "Approach 3: Using Stack. Maintain a stack of bar indices. Iterate through the histogram bars. If the current bar is taller than or equal to the bar at the top of the stack, push the current bar's index onto the stack. If the current bar is shorter than the bar at the top of the stack, pop the top of the stack until we find a bar that is shorter than the current bar. Then, calculate the area of the rectangle formed by the popped bar, using the current index and the index of the bar below the popped bar in the stack to determine the width. The time complexity is O(n) because each bar is pushed and popped at most once. The space complexity is O(n) because the stack can hold up to n elements."
        ],
        "ques_num": 84
    },
    {
        "question": "Maximal Rectangle",
        "description": "Given a binary matrix (a matrix consisting of 0s and 1s), find the area of the largest rectangle containing only 1s.",
        "approaches": [
            "Approach 1: Brute Force. Iterate over all possible combinations of coordinates (x1, y1) and (x2, y2), defining a rectangle with these as opposite corners. For each rectangle, check if it contains only 1s. The area of the largest such rectangle is the answer. Time complexity: O(N^3 * M^3), where N is the number of rows and M is the number of columns, due to iterating over all possible rectangle coordinates O(N^2 * M^2), and iterating over the rectangle defined by two coordinates O(N * M). Space complexity: O(1). This solution is inefficient due to the high time complexity.",
            "Approach 2: Dynamic Programming - Better Brute Force on Histograms. Compute the maximum width of a rectangle that ends at a given coordinate in constant time by keeping track of the number of consecutive ones in each row. Iterate over each row and update the maximum possible width at that point. Once the maximum width for each point is known, compute the maximum rectangle with a rectangle spanning from the original point to the current point using the running minimum of each maximal width. Time complexity: O(N^2 * M). Computing the maximum area for one point takes O(N) time, since it iterates over the values in the same column. This is done for all N * M points, giving O(N) * (N * M) = O(N^2 * M). Space complexity: O(N * M). An equal sized array is allocated to store the maximum width at each point.",
            "Approach 3: Using Histograms - Stack. Break down the input into a set of histograms, with each column being a new histogram. For each row, compute the maximum area of each histogram using a stack-based approach (similar to the 'Largest Rectangle in Histogram' problem). Then, find the global maximum area. Time complexity: O(N * M). Running the stack-based algorithm on each row takes O(M) time. This is done N times, for O(N * M). Space complexity: O(M). An array the size of the number of columns is allocated to store the widths at each row.",
            "Approach 4: Dynamic Programming - Maximum Height at Each Point. For each point, compute the maximum height of the rectangle by iterating upwards until a 0 is reached. Find the maximum width of the rectangle by iterating outwards left and right until a height that doesn't accommodate the maximum height of the rectangle. Given a row matrix[i], keep track of the height, left, and right of each point in the row by defining three arrays - height, left, and right. Time complexity: O(NM). Space complexity: O(M)."
        ],
        "ques_num": 85
    },
    {
        "question": "Partition List",
        "description": "Given the head of a singly linked list and a value `x`, partition the linked list such that all nodes with a value less than `x` come before nodes with a value greater than or equal to `x`. The relative order of the nodes in each of the two partitions should be preserved. Return the head of the partitioned linked list.",
        "approaches": [
            "Approach 1: Brute Force using Additional Space - Create two separate lists, one for elements less than x and another for elements greater than or equal to x. Iterate through the original list, appending each node to the appropriate new list. Finally, concatenate the two lists. This involves creating new nodes, which is unnecessary. Time Complexity: O(N), where N is the number of nodes in the linked list. Space Complexity: O(N) because in the worst case, all nodes may need to be copied into a new list.",
            "Approach 2: Using ArrayLists to Store Values - Iterate through the linked list and store the values less than x in one ArrayList and the values greater than or equal to x in another ArrayList. Then, create a new linked list by iterating through the ArrayLists and creating new nodes with the stored values. Time Complexity: O(N) to traverse the linked list and O(N) to create the new linked list. Space Complexity: O(N) because of the ArrayLists.",
            "Approach 3: Two-Pointer Approach with Dummy Nodes (Optimal) - Initialize two dummy nodes, `before_head` and `after_head`, which point to the heads of the 'before' and 'after' lists, respectively. Iterate through the original linked list. If a node's value is less than `x`, append it to the 'before' list. Otherwise, append it to the 'after' list. Finally, connect the 'before' list to the 'after' list, ensuring the 'after' list is properly terminated with null. Return the head of the 'before' list (excluding the dummy node). Time Complexity: O(N), where N is the number of nodes in the linked list, as we iterate through it once. Space Complexity: O(1), as we only use a constant amount of extra space for the dummy nodes and pointers; we are rearranging the existing nodes rather than creating new ones."
        ],
        "ques_num": 86
    },
    {
        "question": "Scramble String",
        "description": "Given two strings, determine if the second string is a scrambled version of the first string. A scrambled string is defined recursively: it can be created by dividing the string into two non-empty parts, swapping the parts (optionally), and then recursively scrambling each part. Two strings of length 1 are scrambled if they are equal.",
        "approaches": [
            "Approach 1: Brute-force recursion. For every possible split of the first string, check if the second string can be formed by either keeping the split order or swapping the split order and recursively verifying the scrambled property of the substrings. Time complexity is exponential, roughly O(n!), because each split leads to multiple recursive calls. Space complexity is O(n) due to the call stack depth.",
            "Approach 2: Memoized Recursion. The brute-force approach is inefficient due to repeated calculations. We can use memoization to store the results of subproblems (isScramble(substring1, substring2)) in a hashmap or a 3D array. Before making a recursive call, check if the result is already memoized. If so, return the memoized value. This optimization reduces the number of redundant calculations. Time complexity improves to O(n^4), where n is the length of the string, because there are O(n^3) possible subproblems, and we iterate through O(n) possible splits for each subproblem. Space complexity is O(n^3) to store the memoization table plus O(n) for the call stack, resulting in O(n^3).",
            "Approach 3: Dynamic Programming. Build a 3D DP table `dp[length][i][j]` where `dp[length][i][j]` is true if the substring of length `length` in `s1` starting at index `i` is a scrambled version of the substring of length `length` in `s2` starting at index `j`. The base case is when length is 1, `dp[1][i][j] = (s1[i] == s2[j])`. For length > 1, iterate through all possible split points `newLength` and check if `(dp[newLength][i][j] && dp[length - newLength][i + newLength][j + newLength]) || (dp[newLength][i][j + length - newLength] && dp[length - newLength][i + newLength][j])` is true. The final answer is `dp[n][0][0]`. The time complexity is O(n^4) due to the four nested loops (length, i, j, newLength). The space complexity is O(n^3) to store the DP table. This is the most optimal approach because it avoids redundant calculations by systematically building the solution from smaller subproblems."
        ],
        "ques_num": 87
    },
    {
        "question": "Merge Sorted Array",
        "description": "You are given two integer arrays `nums1` and `nums2`, sorted in non-decreasing order, with lengths `m` and `n` respectively. Modify `nums1` in-place to contain the merged, sorted array. The first `m` elements of `nums1` represent the elements to be merged, while the remaining `n` elements are initially 0 and should be used to store the merged elements.",
        "approaches": [
            "Approach 1: Merge and Sort. First, copy all elements from `nums2` into the end of `nums1`. Then, sort the entire `nums1` array using a built-in sorting algorithm. This is a straightforward but inefficient approach. Time complexity: O((n+m)log(n+m)) due to sorting. Space complexity: O(1) or O(n) depending on the sorting algorithm implementation.",
            "Approach 2: Three Pointers (Start From the Beginning). Create a copy of the first `m` elements of `nums1` called `nums1_copy`. Use three pointers: `p1` to iterate through `nums1_copy`, `p2` to iterate through `nums2`, and `p` to write the merged elements into `nums1`. Compare elements at `nums1_copy[p1]` and `nums2[p2]` and write the smaller one into `nums1[p]`, incrementing the corresponding pointer and `p`. Time complexity: O(n+m) because each element is read and written at most once. Space complexity: O(m) because of the extra `nums1_copy` array.",
            "Approach 3: Three Pointers (Start From the End). Initialize three pointers: `p1` to point to the last element of the initial part of `nums1` (index `m-1`), `p2` to point to the last element of `nums2` (index `n-1`), and `p` to point to the last available space in `nums1` (index `m+n-1`). Compare `nums1[p1]` and `nums2[p2]` and write the larger one into `nums1[p]`, decrementing the corresponding pointer and `p`. This approach modifies `nums1` in-place without using extra space. Time complexity: O(n+m) as each element is compared and placed at most once. Space complexity: O(1) because no additional space is used."
        ],
        "ques_num": 88
    },
    {
        "question": "Gray Code",
        "description": "Given an integer n, generate the Gray code sequence for n bits. The Gray code sequence is a sequence of 2^n integers where adjacent numbers differ by only one bit.",
        "approaches": [
            "Approach 1: Backtracking. Generate all possible bit strings of length n and then filter them to keep only sequences where adjacent numbers differ by one bit. This involves recursively exploring all possible bit combinations. The algorithm starts with an empty sequence and iteratively adds bits, checking at each step if the new sequence adheres to the Gray code property. Time complexity is O(n * 2^n * T) because we explore each of the 2^n possible sequences and check each adjacent number. T is the time complexity for validating the sequence. Space complexity is O(n) for the recursion depth.",
            "Approach 2: Recursion. Use the recursive property of Gray codes. The Gray code of n bits can be generated from the Gray code of n-1 bits by reflecting the sequence and adding a '0' to the most significant bit of the original sequence and a '1' to the most significant bit of the reflected sequence. This approach reduces the computational overhead by directly constructing the sequence based on its inherent recursive definition. Time complexity is O(n * 2^n) due to generating 2^n numbers and performing O(n) operations for each. Space complexity is O(n) for recursion depth.",
            "Approach 3: Iteration using XOR. Use the formula G(i) = i ^ (i >> 1) to directly calculate the Gray code for each index i from 0 to 2^n - 1. This approach leverages the bitwise XOR operation to efficiently compute the Gray code sequence without recursion or backtracking. The algorithm iterates through each number from 0 to 2^n - 1, applies the XOR operation, and adds the result to the sequence. This method is the most efficient because it directly computes each Gray code value. Time complexity is O(2^n) because we iterate through all 2^n possible values, and the XOR operation is O(1). Space complexity is O(1) because only a constant amount of extra space is used."
        ],
        "ques_num": 89
    },
    {
        "question": "Subsets II",
        "description": "Given an array of integers that may contain duplicates, find all possible subsets (the power set) of the array including duplicate subsets.",
        "approaches": [
            "Approach 1: Bitmasking. Sort the input array. Iterate through all possible subsets using bit manipulation, where each bit in a mask represents whether an element is present in the subset. Use a set to eliminate duplicate subsets. The time complexity is O(N log N + 2^N * N) due to sorting, iterating through all subsets, and creating each subset. The space complexity is O(2^N) to store all possible subsets in the set.",
            "Approach 2: Cascading (Iterative). Sort the input array. Iterate through the array, and for each element, add it to the existing subsets to create new subsets. Handle duplicates by only adding the duplicate elements to the subsets created in the previous iteration. The time complexity is O(N log N + 2^N * N) due to sorting, iterating through all subsets, and creating each subset. The space complexity is O(2^N) to store all possible subsets.",
            "Approach 3: Backtracking. Sort the input array. Use a recursive helper function to generate all possible subsets. In each recursive call, either include the current element in the subset or exclude it. To avoid duplicate subsets, skip duplicate elements in the input array during the recursive calls. The time complexity is O(N log N + 2^N) due to sorting and generating all subsets. The space complexity is O(N) due to the recursion stack."
        ],
        "ques_num": 90
    },
    {
        "question": "Decode Ways",
        "description": "Given a string of digits, find the number of ways to decode it. Each digit can be mapped to a letter (e.g., '1' -> A, '2' -> B, ..., '26' -> Z).",
        "approaches": [
            "Approach 1: Recursive Approach without Memoization. The algorithm explores all possible decoding paths by recursively calling itself for substrings created by decoding one or two digits at a time. If the first digit is '0' or the two-digit combination is greater than 26, the path is invalid. The time complexity is exponential, O(2^N), where N is the length of the string, because of overlapping subproblems being recomputed. The space complexity is O(N) due to the recursion depth in the worst case.",
            "Approach 2: Iterative Dynamic Programming Approach. This approach uses a DP array of size N+1, where dp[i] stores the number of ways to decode the substring s[0...i-1]. The base cases are dp[0] = 1 (empty string) and dp[1] = 1 if s[0] is not '0', otherwise 0. The algorithm iterates from i = 2 to N+1, and dp[i] is calculated based on whether the last one or two digits can be decoded. Time complexity is O(N) due to the single loop. Space complexity is O(N) due to the DP array.",
            "Approach 3: Iterative Dynamic Programming with Constant Space. This approach optimizes the previous DP solution by observing that only the previous two values in the DP array are needed to calculate the current value. Therefore, instead of storing the entire DP array, only two variables are used to store the last two results. The time complexity remains O(N) due to the single loop. The space complexity is reduced to O(1) because only a constant number of variables are used."
        ],
        "ques_num": 91
    },
    {
        "question": "Reverse Linked List II",
        "description": "Given a singly linked list, reverse the nodes from position `m` to `n`. Solve it in-place and in one pass.",
        "approaches": [
            "Approach 1: Brute Force with Array Copy. Copy the values of the nodes from index `m` to `n` into an array. Reverse the array. Then, iterate from index `m` to `n` in the linked list and update the node values with the reversed array values. This approach is simple but inefficient. It requires extra space for the array. Time complexity: O(N), where N is the number of nodes in the linked list. Space complexity: O(N) in the worst case where m=1 and n=N, and O(n-m) in general.",
            "Approach 2: Iterative Link Reversal with Multiple Passes. First, traverse the linked list to reach the (m-1)th node. Then, iteratively reverse the links between nodes from m to n using three pointers: `prev`, `curr`, and `next`. After reversing the sublist, connect the reversed sublist back to the original list. This approach modifies the links directly but may require careful pointer manipulation. Time complexity: O(N), where N is the number of nodes. Space complexity: O(1).",
            "Approach 3: Iterative Link Reversal with Single Pass. This is an optimized version of the iterative approach. Use a dummy node to handle the case where m=1. Use three pointers: `prev`, `curr`, and `next` to reverse the sublist between nodes m and n. Connect the reversed sublist with the rest of the linked list. This approach is efficient and modifies the links in-place. Time complexity: O(N), where N is the number of nodes. Space complexity: O(1). This is the best approach as it solves the problem in-place with constant extra space and a single pass."
        ],
        "ques_num": 92
    },
    {
        "question": "Restore IP Addresses",
        "description": "Given a string `s` containing only digits, restore it by placing dots to form valid IP addresses. A valid IP address consists of exactly four integers, each integer is between 0 and 255 inclusive, and no integer has leading zeros unless it is exactly 0. Return all possible valid IP addresses that can be formed from `s`. For example, given `s = \"25525511135\"`, return `[\"255.255.11.135\", \"255.255.111.35\"]`.",
        "approaches": [
            "Approach 1: Backtracking. Recursively explore all possible placements of three dots in the string. At each step, check if the current substring is a valid integer (between 0 and 255, and no leading zeros unless it is 0). If it's valid, add the dot and continue the recursion. If we have placed all three dots and the remaining substring is also a valid integer, we have found a valid IP address. This approach explores all possibilities, so the time complexity is O(M^(N-1) * N), where M is the maximum length of each integer(3), and N is the number of integers(4). The space complexity is O(M * N) due to the depth of the recursion and the storage of intermediate results.",
            "Approach 2: Iterative with Nested Loops. Use three nested loops to iterate through all possible lengths of the first three integers (len1, len2, len3).  The ranges of these lengths are optimized to ensure that the remaining part can form a valid fourth integer. Inside the loops, check if all four substrings are valid integers. If they are, concatenate them with dots and add the result to the answer list. This avoids recursion, resulting in a potentially simpler implementation. The time complexity is O(M^(N-1) * N) because of the nested loops and validation of each substring. The space complexity is O(M * N) due to storing the intermediate substrings.",
            "Approach 3: Optimized Backtracking with Early Pruning. Similar to the backtracking approach, but with more aggressive pruning to reduce the search space. Before each recursive call, check if the remaining length of the string is sufficient to form the remaining integers. Also, check if the current substring is a valid integer before proceeding. This approach can significantly reduce the number of recursive calls, especially for invalid input strings. The time complexity is still theoretically O(M^(N-1) * N) in the worst case, but in practice, it is much faster than the naive backtracking approach. The space complexity remains O(M * N)."
        ],
        "ques_num": 93
    },
    {
        "question": "Binary Tree Inorder Traversal",
        "description": "Given the root of a binary tree, return the inorder traversal of its nodes' values.",
        "approaches": [
            "Approach 1: Recursive Inorder Traversal. This approach uses a recursive helper function to traverse the binary tree in inorder fashion (left, root, right). The helper function is called on the left subtree, then the root's value is added to the result list, and finally, the helper function is called on the right subtree. Time complexity: O(n), where n is the number of nodes in the tree. Space complexity: O(n) in the worst case (skewed tree) due to the call stack, and O(log n) on average (balanced tree).",
            "Approach 2: Iterative Inorder Traversal using Stack. This approach uses a stack to simulate the recursive calls. The algorithm pushes the current node and all its left descendants onto the stack. When a node is popped from the stack, its value is added to the result, and then the algorithm processes the right subtree of that node. Time complexity: O(n), where n is the number of nodes in the tree. Space complexity: O(n) in the worst case (skewed tree) where all nodes are in one branch, and O(log n) on average (balanced tree) where the height of the tree dictates the maximum stack size.",
            "Approach 3: Morris Traversal (Threaded Binary Tree). This approach performs inorder traversal without using recursion or a stack. It modifies the tree by creating temporary links (threads) between nodes. For each node, if it has a left child, find the rightmost node in the left subtree and make the current node the right child of that rightmost node. Then, move to the left child. If the current node has no left child, add its value to the result and move to its right child. After the traversal, the threads are removed to restore the original tree structure. Time complexity: O(n), where n is the number of nodes in the tree. Although finding the predecessor node might intuitively seem like O(n log n), amortized analysis shows it's O(n) because each edge is traversed at most twice. Space complexity: O(1) as it uses constant extra space."
        ],
        "ques_num": 94
    },
    {
        "question": "Unique Binary Search Trees II",
        "description": "Given an integer 'n', generate all structurally unique binary search trees (BST) that store values 1 to n.",
        "approaches": [
            "Approach 1: Brute-force recursion. This approach involves generating all possible combinations of nodes to form binary trees and then checking if each tree is a valid BST.  The time complexity is exponential, potentially O(n! * validation_cost), and the space complexity is O(n) for the tree height in the worst case. This approach is inefficient because it generates many invalid BSTs and has a high time complexity.",
            "Approach 2: Recursive generation with BST validation.  Generate left and right subtrees recursively.  For each number 'i' from 1 to 'n', consider 'i' as the root. Recursively generate all possible left subtrees with values from 1 to 'i-1' and all possible right subtrees with values from 'i+1' to 'n'. Combine each left subtree with each right subtree to form a new BST with 'i' as the root.  The time complexity is still high, related to Catalan number, but better than brute force: O(4^n / n^(3/2)). Space complexity: O(4^n / n^(3/2)) due to the storage of the generated trees.",
            "Approach 3: Dynamic Programming with Memoization. Memoize the results of generating BSTs for a given range [start, end]. For each 'i' from start to end, let 'i' be the root.  The left subtree will contain nodes from 'start' to 'i-1', and the right subtree will contain nodes from 'i+1' to 'end'.  Use memoization to avoid redundant calculations. The time complexity is O(n * Catalan(n)) which simplifies to approximately O(4^n / sqrt(n)) and the space complexity is O(Catalan(n)) which is approximately O(4^n / (n^(3/2))). This is optimal because we must generate all possible trees, which corresponds to the catalan number."
        ],
        "ques_num": 95
    },
    {
        "question": "Unique Binary Search Trees",
        "description": "Given a sorted sequence of numbers from 1 to n, how many structurally unique Binary Search Trees (BSTs) can be constructed from this sequence?",
        "approaches": [
            "Approach 1: Recursive Solution (without memoization). This approach directly implements the recursive formula G(n) = sum(G(i-1) * G(n-i)) for i from 1 to n, where G(n) represents the number of unique BSTs for a sequence of length n. The base cases are G(0) = 1 and G(1) = 1. This approach suffers from redundant calculations of overlapping subproblems. Time complexity: Exponential. Space complexity: O(n) due to the recursion depth.",
            "Approach 2: Dynamic Programming. This approach uses dynamic programming to store the results of subproblems G(i) in an array, avoiding redundant calculations. It iterates from i = 2 to n, calculating G(i) using the same recursive formula as in Approach 1, but using the stored values of G(j) for j < i. This significantly improves the time complexity. Time complexity: O(n^2) due to the nested loops. Space complexity: O(n) to store the G(i) values.",
            "Approach 3: Catalan Number Formula. The number of unique BSTs that can be formed from a sequence of length n is given by the nth Catalan number, which can be calculated iteratively using the formula C(n+1) = C(n) * 2 * (2*n + 1) / (n + 2). The algorithm iterates from i = 0 to n-1, calculating the Catalan number for each i and storing it in a single variable to calculate the next one. This approach is the most efficient as it directly computes the result without nested loops or recursion. Time complexity: O(n). Space complexity: O(1) as only a single variable is used."
        ],
        "ques_num": 96
    },
    {
        "question": "Interleaving String",
        "description": "Given three strings, s1, s2, and s3, determine whether s3 can be formed by interleaving s1 and s2, maintaining the original order of characters from each string.",
        "approaches": [
            "Approach 1: Brute Force Recursion. Explore all possible interleavings of s1 and s2. The algorithm recursively chooses a character from either s1 or s2 and appends it to the current interleaved string. If the interleaved string matches s3, return true. The base case is when both s1 and s2 are empty, and the interleaved string matches s3. Time complexity: O(2^(m+n)), where m and n are the lengths of s1 and s2, respectively. Space complexity: O(m+n) due to the recursive call stack.",
            "Approach 2: Recursion with Memoization. Improve the brute-force approach by storing the results of previously computed subproblems in a memoization table. The algorithm maintains a 2D array `memo` to store the result of `isInterleave(i, j, k, memo)` where `i` and `j` are the indices of current characters in `s1` and `s2` respectively, and `k` is the index of current character in `s3`. Before making a recursive call, check if the result is already stored in `memo`. If it is, return the stored result. Time complexity: O(m*n), where m and n are the lengths of s1 and s2, respectively. Space complexity: O(m*n) to store the memoization table and O(m+n) for the recursion stack, resulting in O(m*n).",
            "Approach 3: 2D Dynamic Programming. Use a 2D boolean array `dp` where `dp[i][j]` indicates whether the first `i` characters of `s1` and the first `j` characters of `s2` can interleave to form the first `i+j` characters of `s3`. The algorithm iterates through the `dp` array and fills it based on the following conditions: if the `i`-th character of `s1` matches the `(i+j)`-th character of `s3`, then `dp[i][j] = dp[i-1][j]`. Similarly, if the `j`-th character of `s2` matches the `(i+j)`-th character of `s3`, then `dp[i][j] = dp[i][j-1]`. The final result is stored in `dp[m][n]`. Time complexity: O(m*n), where m and n are the lengths of s1 and s2, respectively. Space complexity: O(m*n) to store the `dp` array.",
            "Approach 4: 1D Dynamic Programming. Optimize the 2D Dynamic Programming approach by using a 1D array. Instead of storing the entire 2D `dp` table, only store the current row. This is possible because the current value of `dp[i][j]` only depends on `dp[i-1][j]` and `dp[i][j-1]`. The algorithm iterates through the strings similar to the 2D DP approach, but updates the 1D array accordingly. Time complexity: O(m*n), where m and n are the lengths of s1 and s2, respectively. Space complexity: O(n), where n is the length of s2. This approach reduces space complexity compared to the 2D DP approach while maintaining the same time complexity."
        ],
        "ques_num": 97
    },
    {
        "question": "Validate Binary Search Tree",
        "description": "Given the root of a binary tree, determine if it is a valid binary search tree (BST). A valid BST is defined as follows: The left subtree of a node contains only nodes with keys less than the node's key. The right subtree of a node contains only nodes with keys greater than the node's key. Both the left and right subtrees must also be binary search trees.",
        "approaches": [
            "Approach 1: Recursive Traversal with Node Value Comparison. Traverse the tree and at each node, check if the node's value is greater than all values in the left subtree and less than all values in the right subtree.  This requires traversing the entire left and right subtrees for each node, leading to a time complexity of O(N*N) in the worst case (skewed tree), and a space complexity of O(H) for the recursion stack where H is the height of the tree (O(N) for a skewed tree). This is inefficient because we repeatedly traverse the same subtrees.",
            "Approach 2: Recursive Traversal with Valid Range. Perform a recursive traversal, passing down a valid range (minimum and maximum values) for each node. For each node, check if its value falls within the valid range. If it doesn't, the tree is not a BST. Recursively check the left subtree with an updated maximum value (the current node's value) and the right subtree with an updated minimum value (the current node's value).  The initial range is negative infinity to positive infinity. This approach has a time complexity of O(N) because each node is visited once, and a space complexity of O(H) for the recursion stack, where H is the height of the tree. This is an improvement over the naive approach as it avoids redundant subtree traversals.",
            "Approach 3: Iterative Inorder Traversal. Perform an iterative inorder traversal of the tree.  During the traversal, keep track of the previously visited node's value.  For each node, check if its value is greater than the previous node's value. If it's not, the tree is not a BST. This approach has a time complexity of O(N) since each node is visited once. The space complexity is O(H) where H is the height of the tree, due to the stack used for the iterative traversal.  This is the most optimal in terms of space since it is iterative and does not rely on recursion."
        ],
        "ques_num": 98
    },
    {
        "question": "Recover Binary Search Tree",
        "description": "Given a Binary Search Tree (BST) where two nodes are swapped, recover the tree to its correct BST structure. Identify the two swapped nodes and swap them back to their proper positions.",
        "approaches": [
            "Approach 1: Inorder Traversal and Sorting. Perform an inorder traversal of the BST and store the node values in an array. Sort the array and then perform another inorder traversal, replacing the node values with the sorted values. This involves constructing an inorder traversal of the tree, identifying the two swapped elements in an almost sorted array, and then traversing the tree again to change node values. The time complexity is O(N log N) due to the sorting step, where N is the number of nodes in the tree. The space complexity is O(N) to store the inorder traversal.",
            "Approach 2: Iterative Inorder Traversal with Swapped Node Detection. Perform an iterative inorder traversal of the BST using a stack. During the traversal, keep track of the previously visited node. If the current node's value is less than the previous node's value, it indicates a potential swap. Identify the two swapped nodes during the traversal. After identifying the two swapped nodes, swap their values. The time complexity is O(N) as we visit each node once. The space complexity is O(N) in the worst case, where the tree is skewed, to store the stack.",
            "Approach 3: Morris Inorder Traversal with Swapped Node Detection. Perform Morris inorder traversal of the BST. This approach avoids using extra space for a stack or recursion. During the traversal, keep track of the previously visited node. If the current node's value is less than the previous node's value, it indicates a potential swap. Identify the two swapped nodes during the traversal. After the traversal, swap the values of the identified nodes. The time complexity is O(N) as each node is visited at most twice. The space complexity is O(1) as it does not use any extra space for the traversal."
        ],
        "ques_num": 99
    },
    {
        "question": "Same Tree",
        "description": "Given the roots of two binary trees `p` and `q`, determine if the two trees are structurally identical and if the nodes have the same value.",
        "approaches": [
            "Approach 1: Naive Recursive Solution with redundant checks. Recursively check if the nodes are not null, if their values are equal, and then recursively call the function for the left and right subtrees. This approach may have redundant null checks. Time complexity: O(N), where N is the number of nodes. Space complexity: O(N) in the worst case of a completely unbalanced tree due to the recursion stack.",
            "Approach 2: Iterative Solution using Deques. Use two deques to perform a level-order traversal on both trees simultaneously. At each step, pop nodes from both deques, check if they are both null, if one is null while the other isn't, or if their values differ. If any of these checks fail, the trees are not the same. Otherwise, add the left and right children of both nodes to their respective deques. Time complexity: O(N), where N is the number of nodes. Space complexity: O(N) in the worst case, where the tree is a perfect fully balanced binary tree, as the queue will store the last level.",
            "Approach 3: Optimized Recursive Solution with concise null checks. Recursively check for the following conditions: If both nodes are null, return true. If one node is null and the other isn't, return false. If the values are different, return false. Otherwise, recursively call the function for the left and right subtrees and return the logical AND of the results. This approach is generally considered the most efficient in terms of code conciseness and readability while maintaining the same time and space complexity. Time complexity: O(N), where N is the number of nodes. Space complexity: O(N) in the worst case of a completely unbalanced tree due to the recursion stack."
        ],
        "ques_num": 100
    },
    {
        "question": "Symmetric Tree",
        "description": "Given the root of a binary tree, determine if it is a mirror of itself (symmetric).",
        "approaches": [
            "Approach 1: Convert the tree to a string representation (e.g., using pre-order traversal including null nodes) and then check if the string is a palindrome.  This is a simple approach but prone to errors if the serialization is not carefully designed to handle all possible tree structures. It also does not handle cases where different tree structures could result in the same string representation. Time complexity: O(N) for traversal and O(N) for palindrome check. Space complexity: O(N) for the string representation.",
            "Approach 2: Iterative approach using a queue. Add the root twice to the queue. While the queue is not empty, take two nodes at a time. Compare their values. Add their children in reverse order to the queue (left of first node with right of second node, right of first node with left of second node). If the queue becomes empty, the tree is symmetric. This avoids recursion, potentially saving stack space, but still requires explicit queue management. Time complexity: O(N), where N is the number of nodes. Space complexity: O(N) in the worst case (complete binary tree).",
            "Approach 3: Recursive approach. Define a recursive helper function `isMirror(node1, node2)` that checks if two trees are mirror images of each other. The base cases are when both nodes are null (return true) or one is null and the other is not (return false). If both nodes are not null, compare their values. If the values are equal, recursively call `isMirror` on the right subtree of `node1` and the left subtree of `node2`, and on the left subtree of `node1` and the right subtree of `node2`. Return true if both recursive calls return true, otherwise return false. This approach directly implements the definition of symmetry and is generally considered the most elegant and intuitive solution. Time complexity: O(N), where N is the number of nodes. Space complexity: O(H) in the average case and O(N) in the worst case (skewed tree), where H is the height of the tree, due to the recursive call stack."
        ],
        "ques_num": 101
    }
]